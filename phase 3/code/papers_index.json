{
    "articles": [
        {
            "id": "f90720ed12e045ac84beb94c27271d6fb8ad48cf",
            "title": "The Lottery Ticket Hypothesis: Training Pruned Neural Networks",
            "authors": [
                "Jonathan Frankle",
                "Michael Carbin"
            ],
            "date": "2018",
            "abstract": "Recent work on neural network pruning indicates that, at training time, neural networks need to be significantly larger in size than is necessary to represent the eventual functions that they learn. This paper articulates a new hypothesis to explain this phenomenon. This conjecture, which we term the \"lottery ticket hypothesis,\" proposes that successful training depends on lucky random initialization of a smaller subcomponent of the network. Larger networks have more of these \"lottery tickets,\" meaning they are more likely to luck out with a subcomponent initialized in a configuration amenable to successful optimization. \nThis paper conducts a series of experiments with XOR and MNIST that support the lottery ticket hypothesis. In particular, we identify these fortuitously-initialized subcomponents by pruning low-magnitude weights from trained networks. We then demonstrate that these subcomponents can be successfully retrained in isolation so long as the subnetworks are given the same initializations as they had at the beginning of the training process. Initialized as such, these small networks reliably converge successfully, often faster than the original network at the same level of accuracy. However, when these subcomponents are randomly reinitialized or rearranged, they perform worse than the original network. In other words, large networks that train successfully contain small subnetworks with initializations conducive to optimization. \nThe lottery ticket hypothesis and its connection to pruning are a step toward developing architectures, initializations, and training strategies that make it possible to solve the same problems with much smaller networks.",
            "references": [
                "34f25a8704614163c4095b3ee2fc969b60de4698",
                "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff",
                "b0bd441a0cc04cdd0d0e469fe4c5184ee148a97d",
                "cc46229a7c47f485e090857cbab6e6bf68c09811",
                "642d0f49b7826adcf986616f4af77e736229990f",
                "049fd80f52c0b1fa4d532945d95a24734b62bdf3",
                "2dfef5635c8c44431ca3576081e6cfe6d65d4862",
                "397de65a9a815ec39b3704a79341d687205bc80a",
                "c2a1cb1612ba21e067a5c3ba478a8d73b796b77a",
                "e8eaf8aedb495b6ae0e174eea11e3cfcdf4a3724"
            ]
        },
        {
            "id": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "title": "Attention is All you Need",
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N. Gomez",
                "Lukasz Kaiser",
                "Illia Polosukhin"
            ],
            "date": "2017",
            "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.",
            "references": [
                "b60abe57bc195616063be10638c6437358c81d1e",
                "cea967b59209c6be22829699f05b8b1ac4dc092d",
                "98445f4172659ec5e891e031d8202c102135c644",
                "032274e57f7d8b456bd255fe76b909b2c1d7458e",
                "735d547fc75e0772d2a78c46a1cc5fad7da1474c",
                "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e",
                "13d9323a8716131911bfda048a40e2cde1a76a46",
                "d76c07211479e233f7c6a6f32d5346c983c5598f",
                "43428880d75b3a14257c3ee9bda054e61eb869c0",
                "510e26733aaff585d65701b9f1be7ca9d5afc586"
            ]
        },
        {
            "id": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova"
            ],
            "date": "2019",
            "abstract": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. \nBERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
            "references": [
                "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
                "0bb4cadc80c0afaf29c57518dc9c06f8fcfa5f38",
                "0c47cad9729c38d9db1f75491b1ee4bd883a5d4e",
                "ac11062f1f368d97f4c826c317bf50dcc13fdb59",
                "8c1b00128e74f1cd92aede3959690615695d5101",
                "93b8da28d006415866bf48f9a6e06b5242129195",
                "687bac2d3320083eb4530bf18bb8f8f721477600",
                "b9de9599d7241459db9213b5cdd7059696f5ef8d",
                "27e98e09cf09bc13c913d01676e5f32624011050",
                "6e795c6e9916174ae12349f5dc3f516570c17ce8"
            ]
        },
        {
            "id": "34f25a8704614163c4095b3ee2fc969b60de4698",
            "title": "Dropout: a simple way to prevent neural networks from overfitting",
            "authors": [
                "Nitish Srivastava",
                "Geoffrey E. Hinton",
                "Alex Krizhevsky",
                "Ilya Sutskever",
                "Ruslan Salakhutdinov"
            ],
            "date": "2014",
            "abstract": "Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \"thinned\" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.",
            "references": [
                "5d5d4f49d6443c8529a6f5ebef5c499d47a869da",
                "5d90f06bb70a0a3dced62413346235c02b1aa086",
                "ec92efde21707ddf4b81f301cd58e2051c1a2443",
                "db869fa192a3222ae4f2d766674a378e47013b1b",
                "8978cf7574ceb35f4c3096be768c7547b28a35d0",
                "3c20df69865df6a627cc45c524869ccc0297048f",
                "de75e4e15e22d4376300e5c968e2db44be29ac9e",
                "d124a098cdc6f99b9a152fcf8afa9327dac583be",
                "85021c84383d18a7a4434d76dc8135fc6bdc0aa6",
                "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd"
            ]
        },
        {
            "id": "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff",
            "title": "Learning both Weights and Connections for Efficient Neural Network",
            "authors": [
                "Song Han",
                "Jeff Pool",
                "John Tran",
                "William J. Dally"
            ],
            "date": "2015",
            "abstract": "Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems. Also, conventional networks fix the architecture before training starts; as a result, training cannot improve the architecture. To address these limitations, we describe a method to reduce the storage and computation required by neural networks by an order of magnitude without affecting their accuracy by learning only the important connections. Our method prunes redundant connections using a three-step method. First, we train the network to learn which connections are important. Next, we prune the unimportant connections. Finally, we retrain the network to fine tune the weights of the remaining connections. On the ImageNet dataset, our method reduced the number of parameters of AlexNet by a factor of 9x, from 61 million to 6.7 million, without incurring accuracy loss. Similar experiments with VGG-16 found that the number of parameters can be reduced by 13x, from 138 million to 10.3 million, again with no loss of accuracy.",
            "references": [
                "642d0f49b7826adcf986616f4af77e736229990f",
                "b0bd441a0cc04cdd0d0e469fe4c5184ee148a97d",
                "fbeaa499e10e98515f7e1c4ad89165e8c0677427",
                "34f25a8704614163c4095b3ee2fc969b60de4698",
                "2a4117849c88d4728c33b1becaa9fb6ed7030725",
                "5e83ab70d0cbc003471e87ec306d27d9c80ecb16",
                "081651b38ff7533550a3adfc1c00da333a8fe86c",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "e7bf9803705f2eb608db1e59e5c7636a3f171916"
            ]
        },
        {
            "id": "b0bd441a0cc04cdd0d0e469fe4c5184ee148a97d",
            "title": "Data-free Parameter Pruning for Deep Neural Networks",
            "authors": [
                "Suraj Srinivas",
                "R. Venkatesh Babu"
            ],
            "date": "2015",
            "abstract": "Deep Neural nets (NNs) with millions of parameters are at the heart of many state-of-the-art computer vision systems today. However, recent works have shown that much smaller models can achieve similar levels of performance. In this work, we address the problem of pruning parameters in a trained NN model. Instead of removing individual weights one at a time as done in previous works, we remove one neuron at a time. We show how similar neurons are redundant, and propose a systematic way to remove them. Our experiments in pruning the densely connected layers show that we can remove upto 85\\% of the total parameters in an MNIST-trained network, and about 35\\% for AlexNet without significantly affecting performance. Our method can be applied on top of most networks with a fully connected layer to give a smaller network.",
            "references": [
                "2a4117849c88d4728c33b1becaa9fb6ed7030725",
                "34f25a8704614163c4095b3ee2fc969b60de4698",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "82b9099ddf092463f497bd48bb112c46ca52c4d1",
                "cd85a549add0c7c7def36aca29837efd24b24080",
                "e15cf50aa89fee8535703b9f9512fca5bfc43327",
                "eb42cf88027de515750f230b23b1a057dc782108",
                "0c908739fbff75f03469d13d4a1a07de3414ee19",
                "e8650503ab80ad7299f0845b1843abf3a97f313a"
            ]
        },
        {
            "id": "cc46229a7c47f485e090857cbab6e6bf68c09811",
            "title": "Understanding Dropout",
            "authors": [
                "Pierre Baldi",
                "Peter Sadowski"
            ],
            "date": "2013",
            "abstract": "Dropout is a relatively new algorithm for training neural networks which relies on stochastically \"dropping out\" neurons during training in order to avoid the co-adaptation of feature detectors. We introduce a general formalism for studying dropout on either units or connections, with arbitrary probability values, and use it to analyze the averaging and regularizing properties of dropout in both linear and non-linear networks. For deep neural networks, the averaging properties of dropout are characterized by three recursive equations, including the approximation of expectations by normalized weighted geometric means. We provide estimates and bounds for these approximations and corroborate the results with simulations. Among other results, we also show how dropout performs stochastic gradient descent on a regularized error function.",
            "references": [
                "327d3df8ea2020882827d6bace1e26c9d24309c2",
                "1366de5bb112746a555e9c0cd00de3ad8628aea8",
                "5d5d4f49d6443c8529a6f5ebef5c499d47a869da",
                "7b0db6135b8dd3e2a9efa86163e91c0cd0fdf660",
                "0688fbcbfb08d7b91238bc90589209b31f97290f",
                "7ab5ceb40c0e267ea6fcdbcaedd327d7b263bb8e",
                "ba15f09796d53adfbe9e78cf79182e59b6045543",
                "fc6b1ff29f2da985cccfa644652bb320d7720d59"
            ]
        },
        {
            "id": "642d0f49b7826adcf986616f4af77e736229990f",
            "title": "Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding",
            "authors": [
                "Song Han",
                "Huizi Mao",
                "William J. Dally"
            ],
            "date": "2016",
            "abstract": "Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems with limited hardware resources. To address this limitation, we introduce \"deep compression\", a three stage pipeline: pruning, trained quantization and Huffman coding, that work together to reduce the storage requirement of neural networks by 35x to 49x without affecting their accuracy. Our method first prunes the network by learning only the important connections. Next, we quantize the weights to enforce weight sharing, finally, we apply Huffman coding. After the first two steps we retrain the network to fine tune the remaining connections and the quantized centroids. Pruning, reduces the number of connections by 9x to 13x; Quantization then reduces the number of bits that represent each connection from 32 to 5. On the ImageNet dataset, our method reduced the storage required by AlexNet by 35x, from 240MB to 6.9MB, without loss of accuracy. Our method reduced the size of VGG-16 by 49x from 552MB to 11.3MB, again with no loss of accuracy. This allows fitting the model into on-chip SRAM cache rather than off-chip DRAM memory. Our compression method also facilitates the use of complex neural networks in mobile applications where application size and download bandwidth are constrained. Benchmarked on CPU, GPU and mobile GPU, compressed network has 3x to 4x layerwise speedup and 3x to 7x better energy efficiency.",
            "references": [
                "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff",
                "e7bf9803705f2eb608db1e59e5c7636a3f171916",
                "a6373454105df0c5511ca5f6cae4d20c48214272",
                "2a4117849c88d4728c33b1becaa9fb6ed7030725",
                "efb5032e6199c80f83309fd866b25be9545831fd",
                "fbeaa499e10e98515f7e1c4ad89165e8c0677427",
                "27a99c21a1324f087b2f144adc119f04137dfd87",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "6bdb186ec4726e00a8051119636d4df3b94043b5"
            ]
        },
        {
            "id": "2dfef5635c8c44431ca3576081e6cfe6d65d4862",
            "title": "Diversity Networks: Neural Network Compression Using Determinantal Point Processes",
            "authors": [
                "Zelda Mariet",
                "Suvrit Sra"
            ],
            "date": "2015",
            "abstract": "We introduce Divnet, a flexible technique for learning networks with diverse neurons. Divnet models neuronal diversity by placing a Determinantal Point Process (DPP) over neurons in a given layer. It uses this DPP to select a subset of diverse neurons and subsequently fuses the redundant neurons into the selected ones. Compared with previous approaches, Divnet offers a more principled, flexible technique for capturing neuronal diversity and thus implicitly enforcing regularization. This enables effective auto-tuning of network architecture and leads to smaller network sizes without hurting performance. Moreover, through its focus on diversity and neuron fusing, Divnet remains compatible with other procedures that seek to reduce memory footprints of networks. We present experimental results to corroborate our claims: for pruning neural networks, Divnet is seen to be notably superior to competing approaches.",
            "references": [
                "b0bd441a0cc04cdd0d0e469fe4c5184ee148a97d",
                "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff",
                "d7bfd8a283a7ed8b43255cfd04909484cd3ade28",
                "87d810fcea61068e8b29f2b75fa1cbb00c190bea",
                "48a17d25d76f9bdf90fdd86d2b3e2739e5bb8016",
                "ec46bcbced500820521e9f65b0f9ffef5a83ae11",
                "a42954d4b9d0ccdf1036e0af46d87a01b94c3516",
                "31f88db95eb5c66b95cd7335b0cd4f27f0f271f2",
                "efb5032e6199c80f83309fd866b25be9545831fd",
                "8ba555d9587688bd3225d71ef9d686dad288e1f1"
            ]
        },
        {
            "id": "049fd80f52c0b1fa4d532945d95a24734b62bdf3",
            "title": "ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression",
            "authors": [
                "Jian-Hao Luo",
                "Jianxin Wu",
                "Weiyao Lin"
            ],
            "date": "2017",
            "abstract": "We propose an efficient and unified framework, namely ThiNet, to simultaneously accelerate and compress CNN models in both training and inference stages. We focus on the filter level pruning, i.e., the whole filter would be discarded if it is less important. Our method does not change the original network structure, thus it can be perfectly supported by any off-the-shelf deep learning libraries. We formally establish filter pruning as an optimization problem, and reveal that we need to prune filters based on statistics information computed from its next layer, not the current layer, which differentiates ThiNet from existing methods. Experimental results demonstrate the effectiveness of this strategy, which has advanced the state-of-the-art. We also show the performance of ThiNet on ILSVRC-12 benchmark. ThiNet achieves 3.31 x FLOPs reduction and 16.63\u00d7 compression on VGG-16, with only 0.52% top-5 accuracy drop. Similar experiments with ResNet-50 reveal that even for a compact network, ThiNet can also reduce more than half of the parameters and FLOPs, at the cost of roughly 1% top-5 accuracy drop. Moreover, the original VGG-16 model can be further pruned into a very small model with only 5.05MB model size, preserving AlexNet level accuracy but showing much stronger generalization ability.",
            "references": [
                "c2a1cb1612ba21e067a5c3ba478a8d73b796b77a",
                "60ae4f18cb53efff0174e3fea7064049737e1e67",
                "e7bf9803705f2eb608db1e59e5c7636a3f171916",
                "642d0f49b7826adcf986616f4af77e736229990f",
                "7601b995303f953955004db7b9b8b206c0e02ff8",
                "e15cf50aa89fee8535703b9f9512fca5bfc43327",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "5e83ab70d0cbc003471e87ec306d27d9c80ecb16",
                "eb42cf88027de515750f230b23b1a057dc782108"
            ]
        },
        {
            "id": "397de65a9a815ec39b3704a79341d687205bc80a",
            "title": "A Deep Neural Network Compression Pipeline: Pruning, Quantization, Huffman Encoding",
            "authors": [
                "Song Han",
                "Huizi Mao",
                "William J. Dally"
            ],
            "date": "2015",
            "abstract": "Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems with limited hardware resources. To address this limitation, We introduce a three stage pipeline: pruning, quantization and Huffman encoding, that work together to reduce the storage requirement of neural networks by 35\u00d7 to 49\u00d7 without affecting their accuracy. Our method first prunes the network by learning only the important connections. Next, we quantize the weights to enforce weight sharing, finally, we apply Huffman encoding. After the first two steps we retrain the network to fine tune the remaining connections and the quantized centroids. Pruning, reduces the number of connections by 9\u00d7 to 13\u00d7; Quantization then reduces the number of bits that represent each connection from 32 to 5. On the ImageNet dataset, our method reduced the storage required by AlexNet by 35\u00d7, from 240MB to 6.9MB, without loss of accuracy. Our method reduced the size of VGG16 by 49\u00d7 from 552MB to 11.3MB, again with no loss of accuracy. This allows fitting the model into on-chip SRAM cache rather than off-chip DRAM memory, which has 180\u00d7 less access energy.",
            "references": [
                "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff",
                "e7bf9803705f2eb608db1e59e5c7636a3f171916",
                "2a4117849c88d4728c33b1becaa9fb6ed7030725",
                "fbeaa499e10e98515f7e1c4ad89165e8c0677427",
                "efb5032e6199c80f83309fd866b25be9545831fd",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "e5ae8ab688051931b4814f6d32b18391f8d1fa8d",
                "e15cf50aa89fee8535703b9f9512fca5bfc43327",
                "27a99c21a1324f087b2f144adc119f04137dfd87"
            ]
        },
        {
            "id": "e8eaf8aedb495b6ae0e174eea11e3cfcdf4a3724",
            "title": "Optimal Brain Surgeon and general network pruning",
            "authors": [
                "Babak Hassibi",
                "David G. Stork",
                "Gregory J. Wolff"
            ],
            "date": "1993",
            "abstract": "The use of information from all second-order derivatives of the error function to perform network pruning (i.e., removing unimportant weights from a trained network) in order to improve generalization, simplify networks, reduce hardware or storage requirements, increase the speed of further training, and, in some cases, enable rule extraction, is investigated. The method, Optimal Brain Surgeon (OBS), is significantly better than magnitude-based methods and Optimal Brain Damage, which often remove the wrong weights. OBS, permits pruning of more weights than other methods (for the same error on the training set), and thus yields better generalization on test data. Crucial to OBS is a recursion relation for calculating the inverse Hessian matrix H/sup -1/ from training data and structural information of the set. OBS deletes the correct weights from a trained XOR network in every case.<<ETX>>",
            "references": [
                "a42954d4b9d0ccdf1036e0af46d87a01b94c3516",
                "5887de8eed53c444b2ef93d8ab9c8cc685cd7ac5",
                "de996c32045df6f7b404dda2a753b6a9becf3c08",
                "1b29884885401d12299a01b0eae099f425dd32e1",
                "111fd833a4ae576cfdbb27d87d2f8fc0640af355",
                "57dc98cfb48247b400cc8decb93380e022864905"
            ]
        },
        {
            "id": "c2a1cb1612ba21e067a5c3ba478a8d73b796b77a",
            "title": "Pruning Filters for Efficient ConvNets",
            "authors": [
                "Hao Li",
                "Asim Kadav",
                "Igor Durdanovic",
                "Hanan Samet",
                "Hans Peter Graf"
            ],
            "date": "2016",
            "abstract": "The success of CNNs in various applications is accompanied by a significant increase in the computation and parameter storage costs. Recent efforts toward reducing these overheads involve pruning and compressing the weights of various layers without hurting original accuracy. However, magnitude-based pruning of weights reduces a significant number of parameters from the fully connected layers and may not adequately reduce the computation costs in the convolutional layers due to irregular sparsity in the pruned networks. We present an acceleration method for CNNs, where we prune filters from CNNs that are identified as having a small effect on the output accuracy. By removing whole filters in the network together with their connecting feature maps, the computation costs are reduced significantly. In contrast to pruning weights, this approach does not result in sparse connectivity patterns. Hence, it does not need the support of sparse convolution libraries and can work with existing efficient BLAS libraries for dense matrix multiplications. We show that even simple filter pruning techniques can reduce inference costs for VGG-16 by up to 34% and ResNet-110 by up to 38% on CIFAR10 while regaining close to the original accuracy by retraining the networks.",
            "references": [
                "7d39283a0fce1c96f57eb20046d09bd95ccc56d7",
                "d559dd84fc473fca7e91b9075675750823935afa",
                "3ed94217fbf29b86d5f1baec90dc33adacb40b58",
                "d5b4721c8188269b120d3d06149a04435753e755",
                "021fc345d40d3e6332cd2ef276e2eaa5e71102e4",
                "8ad35df17ae4064dd174690efb04d347428f1117",
                "751c8884c1e857e675d85d8594c5f9b608005ed5",
                "397de65a9a815ec39b3704a79341d687205bc80a",
                "b64601d509711468f5d085261d463846f36785b2",
                "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff"
            ]
        },
        {
            "id": "b60abe57bc195616063be10638c6437358c81d1e",
            "title": "Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation",
            "authors": [
                "Jie Zhou",
                "Ying Cao",
                "Xuguang Wang",
                "Peng Li",
                "Wei Xu"
            ],
            "date": "2016",
            "abstract": "Neural machine translation (NMT) aims at solving machine translation (MT) problems using neural networks and has exhibited promising results in recent years. However, most of the existing NMT models are shallow and there is still a performance gap between a single NMT model and the best conventional MT system. In this work, we introduce a new type of linear connections, named fast-forward connections, based on deep Long Short-Term Memory (LSTM) networks, and an interleaved bi-directional architecture for stacking the LSTM layers. Fast-forward connections play an essential role in propagating the gradients and building a deep topology of depth 16. On the WMT\u201914 English-to-French task, we achieve BLEU=37.7 with a single attention model, which outperforms the corresponding single shallow model by 6.2 BLEU points. This is the first time that a single NMT model achieves state-of-the-art performance and outperforms the best conventional model by 0.7 BLEU points. We can still achieve BLEU=36.3 even without using an attention mechanism. After special handling of unknown words and model ensembling, we obtain the best score reported to date on this task with BLEU=40.4. Our models are also validated on the more difficult WMT\u201914 English-to-German task.",
            "references": [
                "cea967b59209c6be22829699f05b8b1ac4dc092d",
                "5b791cd374c7109693aaddee2c12d659ae4e3ec0",
                "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
                "54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745",
                "1956c239b3552e030db1b78951f64781101125ed",
                "1938624bb9b0f999536dcc8d8f519810bb4e1b3b",
                "c34e41312b47f60986458759d5cc546c2b53f748",
                "944a1cfd79dbfb6fef460360a0765ba790f4027a",
                "a739ae988ba0e3ff232f4507627dfc282ba7b3f4",
                "85315b64a4c73cb86f156ef5b0a085d6ebc8a65d"
            ]
        },
        {
            "id": "cea967b59209c6be22829699f05b8b1ac4dc092d",
            "title": "Sequence to Sequence Learning with Neural Networks",
            "authors": [
                "Ilya Sutskever",
                "Oriol Vinyals",
                "Quoc V. Le"
            ],
            "date": "2014",
            "abstract": "Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT-14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous state of the art. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.",
            "references": [
                "f9a1b3850dfd837793743565a8af95973d395a4e",
                "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
                "96494e722f58705fa20302fe6179d483f52705b4",
                "6658bbf68995731b2083195054ff45b4eca38b3a",
                "167ad306d84cca2455bc50eb833454de9f2dcd02",
                "0b544dfe355a5070b60986319a3f51fb45d1348e",
                "d0be39ee052d246ae99c082a565aba25b811be2d",
                "96364af2d208ea75ca3aeb71892d2f7ce7326b55",
                "9819b600a828a57e1cde047bbe710d3446b30da5",
                "c20ed3a1600122e6cf03b8ed74d3d2920ad0a8c6"
            ]
        },
        {
            "id": "98445f4172659ec5e891e031d8202c102135c644",
            "title": "Neural Machine Translation in Linear Time",
            "authors": [
                "Nal Kalchbrenner",
                "Lasse Espeholt",
                "Karen Simonyan",
                "A{\\\"a}ron van den Oord",
                "Alex Graves",
                "Koray Kavukcuoglu"
            ],
            "date": "2016",
            "abstract": "We present a novel neural network for processing sequences. The ByteNet is a one-dimensional convolutional neural network that is composed of two parts, one to encode the source sequence and the other to decode the target sequence. The two network parts are connected by stacking the decoder on top of the encoder and preserving the temporal resolution of the sequences. To address the differing lengths of the source and the target, we introduce an efficient mechanism by which the decoder is dynamically unfolded over the representation of the encoder. The ByteNet uses dilation in the convolutional layers to increase its receptive field. The resulting network has two core properties: it runs in time that is linear in the length of the sequences and it sidesteps the need for excessive memorization. The ByteNet decoder attains state-of-the-art performance on character-level language modelling and outperforms the previous best results obtained with recurrent networks. The ByteNet also achieves state-of-the-art performance on character-to-character machine translation on the English-to-German WMT translation task, surpassing comparable neural translation models that are based on recurrent networks with attentional pooling and run in quadratic time. We find that the latent alignment structure contained in the representations reflects the expected alignment between the tokens.",
            "references": [
                "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
                "b60abe57bc195616063be10638c6437358c81d1e",
                "acec46ffd3f6046af97529127d98f1d623816ea4",
                "cea967b59209c6be22829699f05b8b1ac4dc092d",
                "0b544dfe355a5070b60986319a3f51fb45d1348e",
                "dbde7dfa6cae81df8ac19ef500c42db96c3d1edd",
                "5b791cd374c7109693aaddee2c12d659ae4e3ec0",
                "733b821faeebe49b6efcf5369e3b9902b476529e",
                "93499a7c7f699b6630a86fad964536f9423bb6d0",
                "944a1cfd79dbfb6fef460360a0765ba790f4027a"
            ]
        },
        {
            "id": "032274e57f7d8b456bd255fe76b909b2c1d7458e",
            "title": "A Deep Reinforced Model for Abstractive Summarization",
            "authors": [
                "Romain Paulus",
                "Caiming Xiong",
                "Richard Socher"
            ],
            "date": "2018",
            "abstract": "Attentional, RNN-based encoder-decoder models for abstractive summarization have achieved good performance on short input and output sequences. For longer documents and summaries however these models often include repetitive and incoherent phrases. We introduce a neural network model with a novel intra-attention that attends over the input and continuously generated output separately, and a new training method that combines standard supervised word prediction and reinforcement learning (RL). Models trained only with supervised learning often exhibit \"exposure bias\" - they assume ground truth is provided at each step during training. However, when standard word prediction is combined with the global sequence prediction training of RL the resulting summaries become more readable. We evaluate this model on the CNN/Daily Mail and New York Times datasets. Our model obtains a 41.16 ROUGE-1 score on the CNN/Daily Mail dataset, an improvement over previous state-of-the-art models. Human evaluation also shows that our model produces higher quality summaries.",
            "references": [
                "7a67159fc7bc76d0b37930b55005a69b51241635",
                "f37076f426023241f19cdc2fb0a0fd733a6fa7fa",
                "5082a1a13daea5c7026706738f8528391a1e6d59",
                "5ab72d44237533534de8402e30f3ccce25ce30de",
                "668db48c6a79826456341680ee1175dfc4cced71",
                "1bc49abe5145055f1fa259bd4e700b1eb6b7f08d",
                "f77a604410d88307ec5c6331c8b6133272fbaa10",
                "cea967b59209c6be22829699f05b8b1ac4dc092d",
                "2f160ce71f01ac2043de67536ff0e413ff6f58c5",
                "489955574c435169abd72285cfe2f055f538a401"
            ]
        },
        {
            "id": "13d9323a8716131911bfda048a40e2cde1a76a46",
            "title": "Structured Attention Networks",
            "authors": [
                "Yoon Kim",
                "Carl Denton",
                "Luong Hoang",
                "Alexander M. Rush"
            ],
            "date": "2017",
            "abstract": "Attention networks have proven to be an effective approach for embedding categorical inference within a deep neural network. However, for many tasks we may want to model richer structural dependencies without abandoning end-to-end training. In this work, we experiment with incorporating richer structural distributions, encoded using graphical models, within deep networks. We show that these structured attention networks are simple extensions of the basic attention procedure, and that they allow for extending attention beyond the standard soft-selection approach, such as attending to partial segmentations or to subtrees. We experiment with two different classes of structured attention networks: a linear-chain conditional random field and a graph-based parsing model, and describe how these models can be practically implemented as neural network layers. Experiments show that this approach is effective for incorporating structural biases, and structured attention networks outperform baseline attention models on a variety of synthetic and real tasks: tree transduction, neural machine translation, question answering, and natural language inference. We further find that models trained in this way learn interesting unsupervised hidden representations that generalize simple attention.",
            "references": [
                "04d1a26c2516dc14a765112a63ec60dc3cb3de72",
                "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e",
                "162db03ef3cb50a07ff54ae4a1d4ea120e4162f2",
                "e06a68b26bde368883761c9dceb547914b2ecca8",
                "bc82b4f9f202062857958f0336fc28327a75563b",
                "705dcc8eadba137834e4b0359e2d696d4b209f5b",
                "596c882de006e4bb4a93f1fa08a5dd467bee060a",
                "654a3e53fb41d8168798ee0ee61dfab73739b1ed",
                "2846e83d405cbe3bf2f0f3b5f635dd8b3c680c45",
                "2cd8e8f510c89c7c18268e8ad51c061e459ad321"
            ]
        },
        {
            "id": "735d547fc75e0772d2a78c46a1cc5fad7da1474c",
            "title": "Can Active Memory Replace Attention?",
            "authors": [
                "Lukasz Kaiser",
                "Samy Bengio"
            ],
            "date": "2016",
            "abstract": "Several mechanisms to focus attention of a neural network on selected parts of its input or memory have been used successfully in deep learning models in recent years. Attention has improved image classification, image captioning, speech recognition, generative models, and learning algorithmic tasks, but it had probably the largest impact on neural machine translation. Recently, similar improvements have been obtained using alternative mechanisms that do not focus on a single part of a memory but operate on all of it in parallel, in a uniform way. Such mechanism, which we call active memory, improved over attention in algorithmic tasks, image processing, and in generative modelling. So far, however, active memory has not improved over attention for most natural language processing tasks, in particular for machine translation. We analyze this shortcoming in this paper and propose an extended model of active memory that matches existing attention models on neural machine translation and generalizes better to longer sentences. We investigate this model and explain why previous active memory models did not succeed. Finally, we discuss when active memory brings most benefits and where attention can be a better choice.",
            "references": [
                "eb5eb891061c78f4fcbc9deb3df8bca7fd005acd",
                "cea967b59209c6be22829699f05b8b1ac4dc092d",
                "5b791cd374c7109693aaddee2c12d659ae4e3ec0",
                "4d8f2d14af5991d4f0d050d22216825cac3157bd",
                "0811597b0851b7ebe21aadce7cb4daac4664b44f",
                "33108287fbc8d94160787d7b2c7ef249d3ad6437",
                "1eb09fecd75eb27825dce4f964b97f4f5cc399d7",
                "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
                "44d2abe2175df8153f465f6c39b68b76a0d40ab9",
                "2c03df8b48bf3fa39054345bafabfeff15bfd11d"
            ]
        },
        {
            "id": "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e",
            "title": "End-To-End Memory Networks",
            "authors": [
                "Sainbayar Sukhbaatar",
                "Arthur Szlam",
                "Jason Weston",
                "Rob Fergus"
            ],
            "date": "2015",
            "abstract": "We introduce a neural network with a recurrent attention model over a possibly large external memory. The architecture is a form of Memory Network (Weston et al., 2015) but unlike the model in that work, it is trained end-to-end, and hence requires significantly less supervision during training, making it more generally applicable in realistic settings. It can also be seen as an extension of RNNsearch to the case where multiple computational steps (hops) are performed per output symbol. The flexibility of the model allows us to apply it to tasks as diverse as (synthetic) question answering and to language modeling. For the former our approach is competitive with Memory Networks, but with less supervision. For the latter, on the Penn TreeBank and Text8 datasets our approach demonstrates comparable performance to RNNs and LSTMs. In both cases we show that the key concept of multiple computational hops yields improved results.",
            "references": [
                "f9a1b3850dfd837793743565a8af95973d395a4e",
                "71ae756c75ac89e2d731c9c79649562b5768ff39",
                "5522764282c85aea422f1c4dc92ff7e0ca6987bc",
                "9665247ea3421929f9b6ad721f139f11edb1dbb8",
                "44d2abe2175df8153f465f6c39b68b76a0d40ab9",
                "adfcf065e15fd3bc9badf6145034c84dfb08f204",
                "f264e8b33c0d49a692a6ce2c4bcb28588aeb7d97",
                "d38e8631bba0720becdaf7b89f79d9f9dca45d82",
                "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
                "30110856f45fde473f1903f686aa365cf70ed4c7"
            ]
        },
        {
            "id": "d76c07211479e233f7c6a6f32d5346c983c5598f",
            "title": "Multi-task Sequence to Sequence Learning",
            "authors": [
                "Minh-Thang Luong",
                "Quoc V. Le",
                "Ilya Sutskever",
                "Oriol Vinyals",
                "Lukasz Kaiser"
            ],
            "date": "2016",
            "abstract": "Sequence to sequence learning has recently emerged as a new paradigm in supervised learning. To date, most of its applications focused on only one task and not much work explored this framework for multiple tasks. This paper examines three multi-task learning (MTL) settings for sequence to sequence models: (a) the oneto-many setting - where the encoder is shared between several tasks such as machine translation and syntactic parsing, (b) the many-to-one setting - useful when only the decoder can be shared, as in the case of translation and image caption generation, and (c) the many-to-many setting - where multiple encoders and decoders are shared, which is the case with unsupervised objectives and translation. Our results show that training on a small amount of parsing and image caption data can improve the translation quality between English and German by up to 1.5 BLEU points over strong single-task baselines on the WMT benchmarks. Furthermore, we have established a new state-of-the-art result in constituent parsing with 93.0 F1. Lastly, we reveal interesting properties of the two unsupervised learning objectives, autoencoder and skip-thought, in the MTL context: autoencoder helps less in terms of perplexities but more on BLEU scores compared to skip-thought.",
            "references": [
                "cea967b59209c6be22829699f05b8b1ac4dc092d",
                "4aa9f5150b46320f534de4747a2dd0cd7f3fe292",
                "83cf4b2f39bcc802b09fd59b69e23068447b26b7",
                "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
                "93499a7c7f699b6630a86fad964536f9423bb6d0",
                "2826f9dccdcceb113b33ccf2841d488f1419bb30",
                "5fcd41ca42659ff792fc8ee7d535156e8e69f987",
                "d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0",
                "a41b826d23957d6ad4e9e794d20a583a9b567c5d",
                "c3b8367a80181e28c95630b9b63060d895de08ff"
            ]
        },
        {
            "id": "510e26733aaff585d65701b9f1be7ca9d5afc586",
            "title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer",
            "authors": [
                "Noam Shazeer",
                "Azalia Mirhoseini",
                "Krzysztof Maziarz",
                "Andy Davis",
                "Quoc V. Le",
                "Geoffrey E. Hinton",
                "Jeff Dean"
            ],
            "date": "2017",
            "abstract": "The capacity of a neural network to absorb information is limited by its number of parameters. Conditional computation, where parts of the network are active on a per-example basis, has been proposed in theory as a way of dramatically increasing model capacity without a proportional increase in computation. In practice, however, there are significant algorithmic and performance challenges. In this work, we address these challenges and finally realize the promise of conditional computation, achieving greater than 1000x improvements in model capacity with only minor losses in computational efficiency on modern GPU clusters. We introduce a Sparsely-Gated Mixture-of-Experts layer (MoE), consisting of up to thousands of feed-forward sub-networks. A trainable gating network determines a sparse combination of these experts to use for each example. We apply the MoE to the tasks of language modeling and machine translation, where model capacity is critical for absorbing the vast quantities of knowledge available in the training corpora. We present model architectures in which a MoE with up to 137 billion parameters is applied convolutionally between stacked LSTM layers. On large language modeling and machine translation benchmarks, these models achieve significantly better results than state-of-the-art at lower computational cost.",
            "references": [
                "c6f002b73ffe647ef0effd17c9bfbd5cd7adac7d",
                "44ddac48353ead135eef4096859956eaa31be2a5",
                "cf3229e74f912ef365d67d1954441b32ce2573ee",
                "fba71eefd060e30f3516fdd46df9a191cd0aaaf7",
                "66b8d34477cf1736f91fd22b27e37ce0b703c86e",
                "5a5d48986b855b83a7d9df5005bbd155024ce756",
                "4d376d6978dad0374edfa6709c9556b42d3594d3",
                "72e93aa6767ee683de7f001fa72f1314e40a8f35",
                "b60abe57bc195616063be10638c6437358c81d1e",
                "cea967b59209c6be22829699f05b8b1ac4dc092d"
            ]
        },
        {
            "id": "43428880d75b3a14257c3ee9bda054e61eb869c0",
            "title": "Convolutional Sequence to Sequence Learning",
            "authors": [
                "Jonas Gehring",
                "Michael Auli",
                "David Grangier",
                "Denis Yarats",
                "Yann Dauphin"
            ],
            "date": "2017",
            "abstract": "The prevalent approach to sequence to sequence learning maps an input sequence to a variable length output sequence via recurrent neural networks. We introduce an architecture based entirely on convolutional neural networks. Compared to recurrent models, computations over all elements can be fully parallelized during training and optimization is easier since the number of non-linearities is fixed and independent of the input length. Our use of gated linear units eases gradient propagation and we equip each decoder layer with a separate attention module. We outperform the accuracy of the deep LSTM setup of Wu et al. (2016) on both WMT'14 English-German and WMT'14 English-French translation at an order of magnitude faster speed, both on GPU and CPU.",
            "references": [
                "cea967b59209c6be22829699f05b8b1ac4dc092d",
                "f958d4921951e394057a1c4ec33bad9a34e5dad1",
                "eb5eb891061c78f4fcbc9deb3df8bca7fd005acd",
                "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e",
                "b60abe57bc195616063be10638c6437358c81d1e",
                "41f1d50c85d3180476c4c7b3eea121278b0d8474",
                "3d2c6941a9b4608ba52b328369a3352db2092ae0",
                "0b544dfe355a5070b60986319a3f51fb45d1348e",
                "510e26733aaff585d65701b9f1be7ca9d5afc586",
                "0936352b78a52bc5d2b5e3f04233efc56664af51"
            ]
        },
        {
            "id": "0bb4cadc80c0afaf29c57518dc9c06f8fcfa5f38",
            "title": "Semi-supervised sequence tagging with bidirectional language models",
            "authors": [
                "Matthew E. Peters",
                "Waleed Ammar",
                "Chandra Bhagavatula",
                "Russell Power"
            ],
            "date": "2017",
            "abstract": "Pre-trained word embeddings learned from unlabeled text have become a standard component of neural network architectures for NLP tasks. However, in most cases, the recurrent network that operates on word-level representations to produce context sensitive representations is trained on relatively little labeled data. In this paper, we demonstrate a general semi-supervised approach for adding pre- trained context embeddings from bidirectional language models to NLP systems and apply it to sequence labeling tasks. We evaluate our model on two standard datasets for named entity recognition (NER) and chunking, and in both cases achieve state of the art results, surpassing previous systems that use other forms of transfer or joint learning with additional labeled data and task specific gazetteers.",
            "references": [
                "59761abc736397539bdd01ad7f9d91c8607c0457",
                "7ece4e8d31f872d928369ac2cf58a616a7182112",
                "b89926ec5f0046f3a5671d8e68c918ab9cac76fd",
                "bc1022b031dc6c7019696492e8116598097a8c12",
                "6e795c6e9916174ae12349f5dc3f516570c17ce8",
                "ade0c116120b54b57a91da51235108b75c28375a",
                "8dd6aae51e31a72752c4be5cddbdd76dfdc6cda4",
                "26e743d5bd465f49b9538deaf116c15e61b7951f",
                "2c821e2ec8ef976d3abb36fb0dc1946f04208512",
                "189e6bb7523733c4e524214b9e6ae92d4ed50dac"
            ]
        },
        {
            "id": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "title": "Attention is All you Need",
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N. Gomez",
                "Lukasz Kaiser",
                "Illia Polosukhin"
            ],
            "date": "2017",
            "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.",
            "references": [
                "b60abe57bc195616063be10638c6437358c81d1e",
                "cea967b59209c6be22829699f05b8b1ac4dc092d",
                "98445f4172659ec5e891e031d8202c102135c644",
                "032274e57f7d8b456bd255fe76b909b2c1d7458e",
                "735d547fc75e0772d2a78c46a1cc5fad7da1474c",
                "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e",
                "13d9323a8716131911bfda048a40e2cde1a76a46",
                "d76c07211479e233f7c6a6f32d5346c983c5598f",
                "43428880d75b3a14257c3ee9bda054e61eb869c0",
                "510e26733aaff585d65701b9f1be7ca9d5afc586"
            ]
        },
        {
            "id": "0c47cad9729c38d9db1f75491b1ee4bd883a5d4e",
            "title": "Semi-Supervised Sequence Modeling with Cross-View Training",
            "authors": [
                "Kevin Clark",
                "Minh-Thang Luong",
                "Christopher D. Manning",
                "Quoc V. Le"
            ],
            "date": "2018",
            "abstract": "Unsupervised representation learning algorithms such as word2vec and ELMo improve the accuracy of many supervised NLP models, mainly because they can take advantage of large amounts of unlabeled text. However, the supervised models only learn from task-specific labeled data during the main training phase. We therefore propose Cross-View Training (CVT), a semi-supervised learning algorithm that improves the representations of a Bi-LSTM sentence encoder using a mix of labeled and unlabeled data. On labeled examples, standard supervised learning is used. On unlabeled examples, CVT teaches auxiliary prediction modules that see restricted views of the input (e.g., only part of a sentence) to match the predictions of the full model seeing the whole input. Since the auxiliary modules and the full model share intermediate representations, this in turn improves the full model. Moreover, we show that CVT is particularly effective when combined with multi-task learning. We evaluate CVT on five sequence tagging tasks, machine translation, and dependency parsing, achieving state-of-the-art results.",
            "references": [
                "7647a06965d868a4f6451bef0818994100a142e8",
                "0bb4cadc80c0afaf29c57518dc9c06f8fcfa5f38",
                "4aa9f5150b46320f534de4747a2dd0cd7f3fe292",
                "85f94d8098322f8130512b4c6c4627548ce4a6cc",
                "afc2850945a871e72c245818f9bc141bd659b453",
                "ac17cfa150d802750b46220084d850cfdb64d1c1",
                "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
                "cea967b59209c6be22829699f05b8b1ac4dc092d",
                "ee7b883e35d754ae4f71c21bb71f9f03e4ffbb2c",
                "d76c07211479e233f7c6a6f32d5346c983c5598f"
            ]
        },
        {
            "id": "ac11062f1f368d97f4c826c317bf50dcc13fdb59",
            "title": "Dissecting Contextual Word Embeddings: Architecture and Representation",
            "authors": [
                "Matthew E. Peters",
                "Mark Neumann",
                "Luke Zettlemoyer",
                "Wen-tau Yih"
            ],
            "date": "2018",
            "abstract": "Contextual word representations derived from pre-trained bidirectional language models (biLMs) have recently been shown to provide significant improvements to the state of the art for a wide range of NLP tasks. However, many questions remain as to how and why these models are so effective. In this paper, we present a detailed empirical study of how the choice of neural architecture (e.g. LSTM, CNN, or self attention) influences both end task accuracy and qualitative properties of the representations that are learned. We show there is a tradeoff between speed and accuracy, but all architectures learn high quality contextual representations that outperform word embeddings for four challenging NLP tasks. Additionally, all architectures learn representations that vary with network depth, from exclusively morphological based at the word embedding layer through local syntax based in the lower contextual layers to longer range semantics such coreference at the upper layers. Together, these results suggest that unsupervised biLMs, independent of architecture, are learning much more about the structure of language than previously appreciated.",
            "references": [
                "26f7305e4cf293b3daa672f0f75c1b0bac1e873a",
                "3febb2bed8865945e7fddc99efd791887bb7e14f",
                "efef34c1caef102ad5cc052642d75beaaf5adcaf",
                "0bb4cadc80c0afaf29c57518dc9c06f8fcfa5f38",
                "bc8fa64625d9189f5801837e7b133e7fe3c581f7",
                "fd5794fc63d5f19bf83cf7baa36e0aa62cbf6299",
                "82364428995c29b3dcb60c1835548eeff4adcd20",
                "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
                "891ce1687e2befddd19f54e4eef1d3f39c8dbaf7",
                "3aa52436575cf6768a0a1a476601825f6a62e58f"
            ]
        },
        {
            "id": "8c1b00128e74f1cd92aede3959690615695d5101",
            "title": "QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension",
            "authors": [
                "Adams Wei Yu",
                "David Dohan",
                "Minh-Thang Luong",
                "Rui Zhao",
                "Kai Chen",
                "Mohammad Norouzi",
                "Quoc V. Le"
            ],
            "date": "2018",
            "abstract": "Current end-to-end machine reading and question answering (Q\\&A) models are primarily based on recurrent neural networks (RNNs) with attention. Despite their success, these models are often slow for both training and inference due to the sequential nature of RNNs. We propose a new Q\\&A architecture called QANet, which does not require recurrent networks: Its encoder consists exclusively of convolution and self-attention, where convolution models local interactions and self-attention models global interactions. On the SQuAD dataset, our model is 3x to 13x faster in training and 4x to 9x faster in inference, while achieving equivalent accuracy to recurrent models. The speed-up gain allows us to train the model with much more data. We hence combine our model with data generated by backtranslation from a neural machine translation model. On the SQuAD dataset, our single model, trained with augmented data, achieves 84.6 F1 score on the test set, which is significantly better than the best published F1 score of 81.8.",
            "references": [
                "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
                "e94697b98b707f557436e025bdc8498fa261d3bc",
                "93499a7c7f699b6630a86fad964536f9423bb6d0",
                "97e6ed1f7e5de0034f71c370c01f59c87aaf9a72",
                "adc276e6eae7051a027a4c269fb21dae43cadfed",
                "b798cfd967e1a9ca5e7bc995d33a907bf65d1c7f",
                "de0c30321b22c56d637e7c29cb59180f157272a8",
                "ff1861b71eaedba46cb679bbe2c585dbe18f9b19",
                "12e20e4ea572dbe476fd894c5c9a9930cf250dd2",
                "c25a67ad7e8629a9d12b9e2fc356cd73af99a060"
            ]
        },
        {
            "id": "93b8da28d006415866bf48f9a6e06b5242129195",
            "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
            "authors": [
                "Alex Wang",
                "Amanpreet Singh",
                "Julian Michael",
                "Felix Hill",
                "Omer Levy",
                "Samuel R. Bowman"
            ],
            "date": "2018",
            "abstract": "For natural language understanding (NLU) technology to be maximally useful, both practically and as a scientific object of study, it must be general: it must be able to process language in a way that is not exclusively tailored to any one specific task or dataset. In pursuit of this objective, we introduce the General Language Understanding Evaluation benchmark (GLUE), a tool for evaluating and analyzing the performance of models across a diverse range of existing NLU tasks. GLUE is model-agnostic, but it incentivizes sharing knowledge across tasks because certain tasks have very limited training data. We further provide a hand-crafted diagnostic test suite that enables detailed linguistic analysis of NLU models. We evaluate baselines based on current methods for multi-task and transfer learning and find that they do not immediately give substantial improvements over the aggregate performance of training a separate model per task, indicating room for improvement in developing general and robust NLU systems.",
            "references": [
                "ade0c116120b54b57a91da51235108b75c28375a",
                "e242ba1a62eb2595d89afbec2657f33d9ab4abe3",
                "93b4cc549a1bc4bc112189da36c318193d05d806",
                "ceb7dddbd0c51f511c4ba97d328b48fd10d2a7fc",
                "5d833331b0e22ff359db05c62a8bca18c4f04b68",
                "afc2850945a871e72c245818f9bc141bd659b453",
                "8472e999f723a9ccaffc6089b7be1865d8a1b863",
                "f04df4e20a18358ea2f689b4c129781628ef7fc1",
                "8f1c9b656157b1d851563fb42129245701d83175",
                "2997b26ffb8c291ce478bd8a6e47979d5a55c466"
            ]
        },
        {
            "id": "b9de9599d7241459db9213b5cdd7059696f5ef8d",
            "title": "Character-Level Language Modeling with Deeper Self-Attention",
            "authors": [
                "Rami Al-Rfou",
                "Dokook Choe",
                "Noah Constant",
                "Mandy Guo",
                "Llion Jones"
            ],
            "date": "2019",
            "abstract": "LSTMs and other RNN variants have shown strong performance on character-level language modeling. These models are typically trained using truncated backpropagation through time, and it is common to assume that their success stems from their ability to remember long-term contexts. In this paper, we show that a deep (64-layer) transformer model with fixed context outperforms RNN variants by a large margin, achieving state of the art on two popular benchmarks: 1.13 bits per character on text8 and 1.06 on enwik8. To get good results at this depth, we show that it is important to add auxiliary losses, both at intermediate network layers and intermediate sequence positions.",
            "references": [
                "88caa4a0253a8b0076176745ebc072864eab66e1",
                "58c6f890a1ae372958b7decf56132fe258152722",
                "1fd7fc06653723b05abe5f3d1de393ddcf6bdddb",
                "55cf59bfbb25d6363cab87cb747648ebe8a096e5",
                "f9a1b3850dfd837793743565a8af95973d395a4e",
                "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e",
                "2f2d8f8072e5cc9b296fad551f65f183bdbff7aa",
                "4db8cd9117254d21c9c828b8ba2aea58e57ee2c4",
                "84ca430856a92000e90cd728445ca2241c10ddc3",
                "27981998aaef92952eabef2c1490b926f9150c4f"
            ]
        },
        {
            "id": "687bac2d3320083eb4530bf18bb8f8f721477600",
            "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
            "authors": [
                "Richard Socher",
                "Alex Perelygin",
                "Jean Wu",
                "Jason Chuang",
                "Christopher D. Manning",
                "Andrew Y. Ng",
                "Christopher Potts"
            ],
            "date": "2013",
            "abstract": "Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases.",
            "references": [
                "27e38351e48fe4b7da2775bf94341738bc4da07e",
                "81b3b3fe994a9eda6d3f9d2149aa4492d1933975",
                "cfa2646776405d50533055ceb1b7f050e9014dcb",
                "2063745d08868c928455f422202b72146a1960fb",
                "553fb89d5858826c02f26e94262e8958debc777e",
                "da5cd00115f7ec108de8eebf071c5f3f19807df4",
                "d9b0190b06ac7270e9052895f8592beb4959ccfd",
                "57458bc1cffe5caa45a885af986d70f723f406b4",
                "2b669398c4cf2ebe04375c8b1beae20f4ac802fa",
                "6af58c061f2e4f130c3b795c21ff0c7e3903278f"
            ]
        },
        {
            "id": "27e98e09cf09bc13c913d01676e5f32624011050",
            "title": "U-Net: Machine Reading Comprehension with Unanswerable Questions",
            "authors": [
                "Fu Sun",
                "Linyang Li",
                "Xipeng Qiu",
                "Yang P. Liu"
            ],
            "date": "2018",
            "abstract": "Machine reading comprehension with unanswerable questions is a new challenging task for natural language processing. A key subtask is to reliably predict whether the question is unanswerable. In this paper, we propose a unified model, called U-Net, with three important components: answer pointer, no-answer pointer, and answer verifier. We introduce a universal node and thus process the question and its context passage as a single contiguous sequence of tokens. The universal node encodes the fused information from both the question and passage, and plays an important role to predict whether the question is answerable and also greatly improves the conciseness of the U-Net. Different from the state-of-art pipeline models, U-Net can be learned in an end-to-end fashion. The experimental results on the SQuAD 2.0 dataset show that U-Net can effectively predict the unanswerability of questions and achieves an F1 score of 71.7 on SQuAD 2.0.",
            "references": [
                "9a5ba9aee44ab873f3d60b05e2773c693707da88",
                "ff1861b71eaedba46cb679bbe2c585dbe18f9b19",
                "b798cfd967e1a9ca5e7bc995d33a907bf65d1c7f",
                "97e6ed1f7e5de0034f71c370c01f59c87aaf9a72",
                "4d1c856275744c0284312a3a50efb6ca9dc4cd4c",
                "05dd7254b632376973f3a1b4d39485da17814df5",
                "bb6daf3bd95668ea9775d7e06d8b3f6994306cb7",
                "3a7b63b50c64f4ec3358477790e84cbd6be2a0b4",
                "fa025e5d117929361bcf798437957762eb5bb6d4",
                "26b47e35fe6e4260fdf7b7cc98f279a73c277494"
            ]
        },
        {
            "id": "6e795c6e9916174ae12349f5dc3f516570c17ce8",
            "title": "Skip-Thought Vectors",
            "authors": [
                "Ryan Kiros",
                "Yukun Zhu",
                "Ruslan Salakhutdinov",
                "Richard S. Zemel",
                "Raquel Urtasun",
                "Antonio Torralba",
                "Sanja Fidler"
            ],
            "date": "2015",
            "abstract": "We describe an approach for unsupervised learning of a generic, distributed sentence encoder. Using the continuity of text from books, we train an encoder-decoder model that tries to reconstruct the surrounding sentences of an encoded passage. Sentences that share semantic and syntactic properties are thus mapped to similar vector representations. We next introduce a simple vocabulary expansion method to encode words that were not seen as part of training, allowing us to expand our vocabulary to a million words. After training our model, we extract and evaluate our vectors with linear models on 8 tasks: semantic relatedness, paraphrase detection, image-sentence ranking, question-type classification and 4 benchmark sentiment and subjectivity datasets. The end result is an off-the-shelf encoder that can produce highly generic sentence representations that are robust and perform well in practice.",
            "references": [
                "27725a2d2a8cee9bf9fffc6c2167017103aba0fa",
                "0ca7d208ff8d81377e0eaa9723820aeae7a7322d",
                "f527bcfb09f32e6a4a8afc0b37504941c1ba2cee",
                "ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4",
                "cea967b59209c6be22829699f05b8b1ac4dc092d",
                "687bac2d3320083eb4530bf18bb8f8f721477600",
                "d41cfe9b2ada4e09d53262bc75c473d8043936fc",
                "0b544dfe355a5070b60986319a3f51fb45d1348e",
                "ae5e6c6f5513613a161b2c85563f9708bf2e9178",
                "944a1cfd79dbfb6fef460360a0765ba790f4027a"
            ]
        },
        {
            "id": "5d5d4f49d6443c8529a6f5ebef5c499d47a869da",
            "title": "Improving Neural Networks with Dropout",
            "authors": [
                "Nitish Srivastava"
            ],
            "date": "2013",
            "abstract": "Improving Neural Networks with Dropout Nitish Srivastava Master of Science Graduate Department of Computer Science University of Toronto 2013 Deep neural nets with a huge number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from a neural network during training. This prevents the units from co-adapting too much. Dropping units creates thinned networks during training. The number of possible thinned networks is exponential in the number of units in the network. At test time all possible thinned networks are combined using an approximate model averaging procedure. Dropout training followed by this approximate model combination significantly reduces overfitting and gives major improvements over other regularization methods. In this work, we describe models that improve the performance of neural networks using dropout, often obtaining state-of-the-art results on benchmark datasets.",
            "references": [
                "00a817d7cc09f1d690e97432a6ee8c322f94be6a",
                "1366de5bb112746a555e9c0cd00de3ad8628aea8",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "8978cf7574ceb35f4c3096be768c7547b28a35d0",
                "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd",
                "85021c84383d18a7a4434d76dc8135fc6bdc0aa6",
                "db869fa192a3222ae4f2d766674a378e47013b1b",
                "5562a56da3a96dae82add7de705e2bd841eb00fc",
                "d2b62f77cb2864e465aa60bca6c26bb1d2f84963"
            ]
        },
        {
            "id": "5d90f06bb70a0a3dced62413346235c02b1aa086",
            "title": "Learning Multiple Layers of Features from Tiny Images",
            "authors": [
                "Alex Krizhevsky"
            ],
            "date": "2009",
            "abstract": "Groups at MIT and NYU have collected a dataset of millions of tiny colour images from the web. It is, in principle, an excellent dataset for unsupervised training of deep generative models, but previous researchers who have tried this have found it dicult to learn a good set of lters from the images. We show how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex. Using a novel parallelization algorithm to distribute the work among multiple machines connected on a network, we show how training such a model can be done in reasonable time. A second problematic aspect of the tiny images dataset is that there are no reliable class labels which makes it hard to use for object recognition experiments. We created two sets of reliable labels. The CIFAR-10 set has 6000 examples of each of 10 classes and the CIFAR-100 set has 600 examples of each of 100 non-overlapping classes. Using these labels, we show that object recognition is signicantly improved by pre-training a layer of features on a large set of unlabeled tiny images.",
            "references": [
                "54d2b5c64a67f65c5dd812b89e07973f97699552",
                "73e93d0346e8eee6c2ab45e46c26eaafb66e12a8",
                "71e3d9fc53ba14c2feeb7390f0dc99076553b05a",
                "43c8a545f7166659e9e21c88fe234e0323855216",
                "939d584316be99e2db3fec3fbf7d71f22a477f67",
                "08d0ea90b53aba0008d25811268fe46562cfb38c",
                "46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e",
                "4f7476037408ac3d993f5088544aab427bc319c1",
                "73d6a26f407db77506959fdf3f7b853e44f3844a",
                "68c03788224000794d5491ab459be0b2a2c38677"
            ]
        },
        {
            "id": "ec92efde21707ddf4b81f301cd58e2051c1a2443",
            "title": "Fast dropout training",
            "authors": [
                "Sida I. Wang",
                "Christopher D. Manning"
            ],
            "date": "2013",
            "abstract": "Preventing feature co-adaptation by encouraging independent contributions from different features often improves classification and regression performance. Dropout training (Hinton et al., 2012) does this by randomly dropping out (zeroing) hidden units and input features during training of neural networks. However, repeatedly sampling a random subset of input features makes training much slower. Based on an examination of the implied objective function of dropout training, we show how to do fast dropout training by sampling from or integrating a Gaussian approximation, instead of doing Monte Carlo optimization of this objective. This approximation, justified by the central limit theorem and empirical evidence, gives an order of magnitude speedup and more stability. We show how to do fast dropout training for classification, regression, and multilayer neural networks. Beyond dropout, our technique is extended to integrate out other types of noise and small image transformations.",
            "references": [
                "1366de5bb112746a555e9c0cd00de3ad8628aea8",
                "3c20df69865df6a627cc45c524869ccc0297048f",
                "c3ecd8e19e016d15670c8953b4b9afaa5186b0f3",
                "05a8d8f1d2dadf01c35a363b1c37eed1dd27120f",
                "03a460c8ca331d36e8f2e11edd49e7dbc35c7e43",
                "90929a6aa901ba958eb4960aeeb594c752e08369",
                "c6db1c92fc28fff14434b645861c0f4df5065e9e",
                "7abda1941534d3bb558dd959025d67f1df526303",
                "cfa2646776405d50533055ceb1b7f050e9014dcb",
                "dc0975ae518a5b30e60fde23a41c74bafd7c6f8c"
            ]
        },
        {
            "id": "db869fa192a3222ae4f2d766674a378e47013b1b",
            "title": "Bayesian learning for neural networks",
            "authors": [
                "Geoffrey E. Hinton",
                "Radford M. Neal"
            ],
            "date": "1995",
            "abstract": "From the Publisher: \nArtificial \"neural networks\" are now widely used as flexible models for regression classification applications, but questions remain regarding what these models mean, and how they can safely be used when training data is limited. Bayesian Learning for Neural Networks shows that Bayesian methods allow complex neural network models to be used without fear of the \"overfitting\" that can occur with traditional neural network learning methods. Insight into the nature of these complex Bayesian models is provided by a theoretical investigation of the priors over functions that underlie them. Use of these models in practice is made possible using Markov chain Monte Carlo techniques. Both the theoretical and computational aspects of this work are of wider statistical interest, as they contribute to a better understanding of how Bayesian methods can be applied to complex problems. Presupposing only the basic knowledge of probability and statistics, this book should be of interest to many researchers in statistics, engineering, and artificial intelligence. Software for Unix systems that implements the methods described is freely available over the Internet.",
            "references": [
                "fc053fd3feade79df85fd0612d7f817f5ae3cd44",
                "c528d4eb732bf4de66566ff7b502b3311560cb08",
                "25c9f33aceac6dcff357727cbe2faf145b01d13c",
                "a34e35dbbc6911fa7b94894dffdc0076a261b6f0",
                "cc278353721406a248bf733e40cdecbda8ff3a48",
                "d275cf94e620bf5b3776bba8a88acccdcfcd9a19",
                "5104689e412832ea5c3af39e86321e93f298d849",
                "1f462943c8d0af69c12a09058251848324135e5a",
                "906e33843520fa2395c72d71f8d20a1a5d9cd989",
                "d5ae04ca51e76d69f5ad15ba40a3eea520d3860d"
            ]
        },
        {
            "id": "3c20df69865df6a627cc45c524869ccc0297048f",
            "title": "Learning with Marginalized Corrupted Features",
            "authors": [
                "Laurens van der Maaten",
                "Minmin Chen",
                "Stephen Tyree",
                "Kilian Q. Weinberger"
            ],
            "date": "2013",
            "abstract": "The goal of machine learning is to develop predictors that generalize well to test data. Ideally, this is achieved by training on very large (infinite) training data sets that capture all variations in the data distribution. In the case of finite training data, an effective solution is to extend the training set with artificially created examples--which, however, is also computationally costly. We propose to corrupt training examples with noise from known distributions within the exponential family and present a novel learning algorithm, called marginalized corrupted features (MCF), that trains robust predictors by minimizing the expected value of the loss function under the corrupting distribution-- essentially learning with infinitely many (corrupted) training examples. We show empirically on a variety of data sets that MCF classifiers can be trained efficiently, may generalize substantially better to test data, and are more robust to feature deletion at test time.",
            "references": [
                "c5ee421735abee2669a687dd8cad95376a4b7fee",
                "c3ecd8e19e016d15670c8953b4b9afaa5186b0f3",
                "843959ffdccf31c6694d135fad07425924f785b1",
                "6dd9bb6b38e5b84616e207f00a181dbadce06937",
                "be9a17321537d9289875fe475b71f4821457b435",
                "1366de5bb112746a555e9c0cd00de3ad8628aea8",
                "3554953715a4d7af3d4c9201d4080899b84fbad7",
                "8db26a22942404bd435909a16bb3a50cd67b4318",
                "fcba51774867c77f491581d3625d375a0a8f473b",
                "5ac5fbae8a7faf2e9bd49ad01106cec4a2d8f20a"
            ]
        },
        {
            "id": "8978cf7574ceb35f4c3096be768c7547b28a35d0",
            "title": "A Fast Learning Algorithm for Deep Belief Nets",
            "authors": [
                "Geoffrey E. Hinton",
                "Simon Osindero",
                "Yee Whye Teh"
            ],
            "date": "2006",
            "abstract": "We show how to use complementary priors to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.",
            "references": [
                "a120c05ad7cd4ce2eb8fb9697e16c7c4877208a5",
                "709b4bfc5198336ba5d70da987889a157f695c1e",
                "b95799a25def71b100bd12e7ebb32cbcee6590bf",
                "14d2d9b2e4c29fe105bfbb31f9749b60690303a7",
                "5562a56da3a96dae82add7de705e2bd841eb00fc",
                "162d958ff885f1462aeda91cd72582323fd6a1f4",
                "9360e5ce9c98166bb179ad479a9d2919ff13d022",
                "2077d0f30507d51a0d3bbec4957d55e817d66a59",
                "2184fb6d32bc46f252b940035029273563c4fc82",
                "9f87a11a523e4680e61966e36ea2eac516096f23"
            ]
        },
        {
            "id": "de75e4e15e22d4376300e5c968e2db44be29ac9e",
            "title": "Simplifying Neural Networks by Soft Weight-Sharing",
            "authors": [
                "Steven J. Nowlan",
                "Geoffrey E. Hinton"
            ],
            "date": "1992",
            "abstract": "One way of simplifying neural networks so they generalize better is to add an extra term to the error function that will penalize complexity. Simple versions of this approach include penalizing the sum of the squares of the weights or penalizing the number of nonzero weights. We propose a more complicated penalty term in which the distribution of weight values is modeled as a mixture of multiple gaussians. A set of weights is simple if the weights have high probability density under the mixture model. This can be achieved by clustering the weights into subsets with the weights in each cluster having very similar values. Since we do not know the appropriate means or variances of the clusters in advance, we allow the parameters of the mixture model to adapt at the same time as the network learns. Simulations on two different problems demonstrate that this complexity term is more effective than previous complexity terms.",
            "references": [
                "59fa47fc237a0781b4bf1c84fedb728d20db26a1",
                "4a42b2104ca8ff891ae77c40a915d4c94c8f8428",
                "25406e6733a698bfc4ac836f8e74f458e75dad4f",
                "2cee043045b529fceda7964a70e626d45657245a",
                "f8830ea439ca695e7dd848275e534f1024c2fe8a",
                "6f3175b3930d0c71495a52a7bccb3889e5f33520",
                "e7297db245c3feb1897720b173a59fe7e36babb7",
                "c83684f6207697c12850db423fd9747572cf1784",
                "82fa37d5be8e747131a5857992cc33bb95469ce3",
                "d9b824794b2df1ae5708b8a4ba9c6c69c8eef93a"
            ]
        },
        {
            "id": "d124a098cdc6f99b9a152fcf8afa9327dac583be",
            "title": "Dropout Training as Adaptive Regularization",
            "authors": [
                "Stefan Wager",
                "Sida I. Wang",
                "Percy Liang"
            ],
            "date": "2013",
            "abstract": "Dropout and other feature noising schemes control overfitting by artificially corrupting the training data. For generalized linear models, dropout performs a form of adaptive regularization. Using this viewpoint, we show that the dropout regularizer is first-order equivalent to an L2 regularizer applied after scaling the features by an estimate of the inverse diagonal Fisher information matrix. We also establish a connection to AdaGrad, an online learning algorithm, and find that a close relative of AdaGrad operates by repeatedly solving linear dropout-regularized problems. By casting dropout as regularization, we develop a natural semi-supervised algorithm that uses unlabeled data to create a better adaptive regularizer. We apply this idea to document classification tasks, and show that it consistently boosts the performance of dropout training, improving on state-of-the-art results on the IMDB reviews dataset.",
            "references": [
                "ec92efde21707ddf4b81f301cd58e2051c1a2443",
                "32ee75315fd7050bd7411087d9b3c7cf67b82b63",
                "3c20df69865df6a627cc45c524869ccc0297048f",
                "f69b22f0b91c71cbe7dc15f96afa0df6683e1ec6",
                "c3ecd8e19e016d15670c8953b4b9afaa5186b0f3",
                "3e1638d1ce6ec0d18c82fb3235a521db0a559da2",
                "1366de5bb112746a555e9c0cd00de3ad8628aea8",
                "8a9a10170ee907acb3e582742bec5fa09116f302",
                "0d1e90fa2457d34e6efead247a1a75ef76a48160",
                "0e0801da1a187d90862cd00ce7f12222ff965ef0"
            ]
        },
        {
            "id": "85021c84383d18a7a4434d76dc8135fc6bdc0aa6",
            "title": "Deep Boltzmann Machines",
            "authors": [
                "Ruslan Salakhutdinov",
                "Geoffrey E. Hinton"
            ],
            "date": "2009",
            "abstract": "We present a new learning algorithm for Boltzmann machines that contain many layers of hidden variables. Data-dependent expectations are estimated using a variational approximation that tends to focus on a single mode, and dataindependent expectations are approximated using persistent Markov chains. The use of two quite different techniques for estimating the two types of expectation that enter into the gradient of the log-likelihood makes it practical to learn Boltzmann machines with multiple hidden layers and millions of parameters. The learning can be made more efficient by using a layer-by-layer \u201cpre-training\u201d phase that allows variational inference to be initialized with a single bottomup pass. We present results on the MNIST and NORB datasets showing that deep Boltzmann machines learn good generative models and perform well on handwritten digit and visual object recognition tasks.",
            "references": [
                "0b718a3f9dae8abc741411aed5fe5d423079200f",
                "8978cf7574ceb35f4c3096be768c7547b28a35d0",
                "a120c05ad7cd4ce2eb8fb9697e16c7c4877208a5",
                "73d6a26f407db77506959fdf3f7b853e44f3844a",
                "3dc3a0efe58eaf8564ca1965c0ffd23ec495b83f",
                "9360e5ce9c98166bb179ad479a9d2919ff13d022",
                "9f87a11a523e4680e61966e36ea2eac516096f23",
                "39756c8a5ac11462e7df98ef7f7baf5b130ec5c9"
            ]
        },
        {
            "id": "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd",
            "title": "Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion",
            "authors": [
                "Pascal Vincent",
                "Hugo Larochelle",
                "Isabelle Lajoie",
                "Yoshua Bengio",
                "Pierre-Antoine Manzagol"
            ],
            "date": "2010",
            "abstract": "We explore an original strategy for building deep networks, based on stacking layers of denoising autoencoders which are trained locally to denoise corrupted versions of their inputs. The resulting algorithm is a straightforward variation on the stacking of ordinary autoencoders. It is however shown on a benchmark of classification problems to yield significantly lower classification error, thus bridging the performance gap with deep belief networks (DBN), and in several cases surpassing it. Higher level representations learnt in this purely unsupervised fashion also help boost the performance of subsequent SVM classifiers. Qualitative experiments show that, contrary to ordinary autoencoders, denoising autoencoders are able to learn Gabor-like edge detectors from natural image patches and larger stroke detectors from digit images. This work clearly establishes the value of using a denoising criterion as a tractable unsupervised objective to guide the learning of useful higher level representations.",
            "references": [
                "8978cf7574ceb35f4c3096be768c7547b28a35d0",
                "202cbbf671743aefd380d2f23987bd46b9caaf97",
                "e5013a8b793bc3f9f08411a1b37e571d72491a2a",
                "46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e",
                "b543de6755fc1612b2fb449e0282727d0835d9cf"
            ]
        },
        {
            "id": "fbeaa499e10e98515f7e1c4ad89165e8c0677427",
            "title": "Improving the speed of neural networks on CPUs",
            "authors": [
                "Vincent Vanhoucke",
                "Andrew W. Senior",
                "Mark Z. Mao"
            ],
            "date": "2011",
            "abstract": "Recent advances in deep learning have made the use of large, deep neural networks with tens of millions of parameters suitable for a number of applications that require real-time processing. The sheer size of these networks can represent a challenging computational burden, even for modern CPUs. For this reason, GPUs are routinely used instead to train and run such networks. This paper is a tutorial for students and researchers on some of the techniques that can be used to reduce this computational cost considerably on modern x86 CPUs. We emphasize data layout, batching of the computation, the use of SSE2 instructions, and particularly leverage SSSE3 and SSE4 fixed-point instructions which provide a 3\u00d7 improvement over an optimized floating-point baseline. We use speech recognition as an example task, and show that a real-time hybrid hidden Markov model / neural network (HMM/NN) large vocabulary system can be built with a 10\u00d7 speedup over an unoptimized baseline and a 4\u00d7 speedup over an aggressively optimized floating-point baseline at no cost in accuracy. The techniques described extend readily to neural network training and provide an effective alternative to the use of specialized hardware.",
            "references": [
                "94fd94b7ebcdd80e47706376aa0540cbeb009262",
                "fa5cf89c59b834ec7573673657c99c77f53f7add",
                "e337c5e4c23999c36f64bcb33ebe6b284e1bcbf1",
                "80664dab16a1f18ce1998e38a03f080c5e98363a",
                "a4eb9f4fad5c5a1935c6d0532e2c765ee29b0b37",
                "0409187ebfce03de95677aaeb499e8f1953bdbaf",
                "0ea90fac0958d84bcf4a2875c2b169478358b480",
                "8a0a14d8f84fcd8003cc0417cb97b2455dac3eee"
            ]
        },
        {
            "id": "2a4117849c88d4728c33b1becaa9fb6ed7030725",
            "title": "Memory Bounded Deep Convolutional Networks",
            "authors": [
                "Maxwell D. Collins",
                "Pushmeet Kohli"
            ],
            "date": "2014",
            "abstract": "In this work, we investigate the use of sparsity-inducing regularizers during training of Convolution Neural Networks (CNNs). These regularizers encourage that fewer connections in the convolution and fully connected layers take non-zero values and in effect result in sparse connectivity between hidden units in the deep network. This in turn reduces the memory and runtime cost involved in deploying the learned CNNs. We show that training with such regularization can still be performed using stochastic gradient descent implying that it can be used easily in existing codebases. Experimental evaluation of our approach on MNIST, CIFAR, and ImageNet datasets shows that our regularizers can result in dramatic reductions in memory requirements. For instance, when applied on AlexNet, our method can reduce the memory consumption by a factor of four with minimal loss in accuracy.",
            "references": [
                "e15cf50aa89fee8535703b9f9512fca5bfc43327",
                "021fc345d40d3e6332cd2ef276e2eaa5e71102e4",
                "b64601d509711468f5d085261d463846f36785b2",
                "5e83ab70d0cbc003471e87ec306d27d9c80ecb16",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "843959ffdccf31c6694d135fad07425924f785b1",
                "5d90f06bb70a0a3dced62413346235c02b1aa086",
                "aa7bfd2304201afbb19971ebde87b17e40242e91",
                "3127190433230b3dc1abd0680bb58dced4bcd90e"
            ]
        },
        {
            "id": "5e83ab70d0cbc003471e87ec306d27d9c80ecb16",
            "title": "Network In Network",
            "authors": [
                "Min Lin",
                "Qiang Chen",
                "Shuicheng Yan"
            ],
            "date": "2014",
            "abstract": "We propose a novel deep network structure called \"Network In Network\" (NIN) to enhance model discriminability for local patches within the receptive field. The conventional convolutional layer uses linear filters followed by a nonlinear activation function to scan the input. Instead, we build micro neural networks with more complex structures to abstract the data within the receptive field. We instantiate the micro neural network with a multilayer perceptron, which is a potent function approximator. The feature maps are obtained by sliding the micro networks over the input in a similar manner as CNN; they are then fed into the next layer. Deep NIN can be implemented by stacking mutiple of the above described structure. With enhanced local modeling via the micro network, we are able to utilize global average pooling over feature maps in the classification layer, which is easier to interpret and less prone to overfitting than traditional fully connected layers. We demonstrated the state-of-the-art classification performances with NIN on CIFAR-10 and CIFAR-100, and reasonable performances on SVHN and MNIST datasets.",
            "references": [
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "f9def788d4ae040edb8bde18b8aeea635444a4d1",
                "5d90f06bb70a0a3dced62413346235c02b1aa086",
                "822f3b9a392a9abccdaa7ef5ae4183d2d4d3d6db",
                "0abb49fe138e8fb7332c26b148a48d0db39724fc",
                "5d5d4f49d6443c8529a6f5ebef5c499d47a869da",
                "523b12db4004b89284387f978c2af8ae0e79d54b",
                "b3d8dffb73bc93de239998548386c84177caa2ad",
                "38f35dd624cd1cf827416e31ac5e0e0454028eca"
            ]
        },
        {
            "id": "081651b38ff7533550a3adfc1c00da333a8fe86c",
            "title": "How transferable are features in deep neural networks?",
            "authors": [
                "Jason Yosinski",
                "Jeff Clune",
                "Yoshua Bengio",
                "Hod Lipson"
            ],
            "date": "2014",
            "abstract": "Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the first layer they learn features similar to Gabor filters and color blobs. Such first-layer features appear not to be specific to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to specific by the last layer of the network, but this transition has not been studied extensively. In this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Transferability is negatively affected by two distinct issues: (1) the specialization of higher layer neurons to their original task at the expense of performance on the target task, which was expected, and (2) optimization difficulties related to splitting networks between co-adapted neurons, which was not expected. In an example network trained on ImageNet, we demonstrate that either of these two issues may dominate, depending on whether features are transferred from the bottom, middle, or top of the network. We also document that the transferability of features decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features. A final surprising result is that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after fine-tuning to the target dataset.",
            "references": [
                "b8de958fead0d8a9619b55c7299df3257c624a96",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "3e58d9800aa31e5db89d99dcd33e5786b7837bfd",
                "1a2a770d23b4a171fa81de62a78a3deb0588f238",
                "51e93552fe55be91a5711ff2aabc04b742503e68",
                "1109b663453e78a59e4f66446d71720ac58cec25",
                "1e80f755bcbf10479afd2338cec05211fdbd325c",
                "1366de5bb112746a555e9c0cd00de3ad8628aea8",
                "1f88427d7aa8225e47f946ac41a0667d7b69ac52"
            ]
        },
        {
            "id": "e7bf9803705f2eb608db1e59e5c7636a3f171916",
            "title": "Compressing Deep Convolutional Networks using Vector Quantization",
            "authors": [
                "Yunchao Gong",
                "Liu Liu",
                "Ming Yang",
                "Lubomir D. Bourdev"
            ],
            "date": "2014",
            "abstract": "Deep convolutional neural networks (CNN) has become the most promising method for object recognition, repeatedly demonstrating record breaking results for image classification and object detection in recent years. However, a very deep CNN generally involves many layers with millions of parameters, making the storage of the network model to be extremely large. This prohibits the usage of deep CNNs on resource limited hardware, especially cell phones or other embedded devices. In this paper, we tackle this model storage issue by investigating information theoretical vector quantization methods for compressing the parameters of CNNs. In particular, we have found in terms of compressing the most storage demanding dense connected layers, vector quantization methods have a clear gain over existing matrix factorization methods. Simply applying k-means clustering to the weights or conducting product quantization can lead to a very good balance between model size and recognition accuracy. For the 1000-category classification task in the ImageNet challenge, we are able to achieve 16-24 times compression of the network with only 1% loss of classification accuracy using the state-of-the-art CNN.",
            "references": [
                "6d77482b5e3478f4616f7467054ad50505207958",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "eb42cf88027de515750f230b23b1a057dc782108",
                "a99add9d76d849a8d47b93532703e4ca0f683b92",
                "021fc345d40d3e6332cd2ef276e2eaa5e71102e4",
                "a7621b4ec18719b08f3a2a444b6d37a2e20227b7",
                "fbeaa499e10e98515f7e1c4ad89165e8c0677427",
                "6270baedeba28001cd1b563a199335720d6e0fe0",
                "e5ae8ab688051931b4814f6d32b18391f8d1fa8d"
            ]
        },
        {
            "id": "82b9099ddf092463f497bd48bb112c46ca52c4d1",
            "title": "High-Performance Neural Networks for Visual Object Classification",
            "authors": [
                "Dan C. Ciresan",
                "Ueli Meier",
                "Jonathan Masci",
                "Luca Maria Gambardella",
                "J{\\\"u}rgen Schmidhuber"
            ],
            "date": "2011",
            "abstract": "We present a fast, fully parameterizable GPU implementation of Convolutional Neural Network variants. Our feature extractors are neither carefully designed nor pre-wired, but rather learned in a supervised way. Our deep hierarchical architectures achieve the best published results on benchmarks for object classification (NORB, CIFAR10) and handwritten digit recognition (MNIST), with error rates of 2.53%, 19.51%, 0.35%, respectively. Deep nets trained by simple back-propagation perform better than more shallow ones. Learning is surprisingly rapid. NORB is completely trained within five epochs. Test error rates on MNIST drop to 2.42%, 0.97% and 0.48% after 1, 3 and 17 epochs, respectively.",
            "references": [
                "3fa5450f1c0795527939cfef5fbe3912c4dab3ab",
                "5d21006fa32ff69f6b0a646f26ce0db84f2f4d33",
                "5a2668bf420d8509a4dfa28e1cdcdac14c649975",
                "2cc157afda51873c30b195fff56e917b9c06b853",
                "be9a17321537d9289875fe475b71f4821457b435",
                "b98cd08b75ebf2bd1d1ec47c51ef75777a7e64bd",
                "5d90f06bb70a0a3dced62413346235c02b1aa086",
                "581528b2215e017eba96ef4ee16d33a74645755f",
                "162d958ff885f1462aeda91cd72582323fd6a1f4",
                "d46fd54609e09bcd135fd28750003185a5ee4125"
            ]
        },
        {
            "id": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "title": "ImageNet Classification with Deep Convolutional Neural Networks",
            "authors": [
                "Alex Krizhevsky",
                "Ilya Sutskever",
                "Geoffrey E. Hinton"
            ],
            "date": "2012",
            "abstract": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overriding in the fully-connected layers we employed a recently-developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.",
            "references": [
                "bea5780d621e669e8069f05d0f2fc0db9df4b50f",
                "82b9099ddf092463f497bd48bb112c46ca52c4d1",
                "398c296d0cc7f9d180f84969f8937e6d3a413796",
                "5d90f06bb70a0a3dced62413346235c02b1aa086",
                "c43025c429b1fbf6f1379f61801a1b40834d62e7",
                "3a4a53fe47036ac89dad070ab87a9d8795b139b1",
                "5562a56da3a96dae82add7de705e2bd841eb00fc",
                "f354310098e09c1e1dc88758fca36767fd9d084d",
                "1e80f755bcbf10479afd2338cec05211fdbd325c",
                "1f88427d7aa8225e47f946ac41a0667d7b69ac52"
            ]
        },
        {
            "id": "cd85a549add0c7c7def36aca29837efd24b24080",
            "title": "FitNets: Hints for Thin Deep Nets",
            "authors": [
                "Adriana Romero",
                "Nicolas Ballas",
                "Samira Ebrahimi Kahou",
                "Antoine Chassang",
                "Carlo Gatta",
                "Yoshua Bengio"
            ],
            "date": "2015",
            "abstract": "While depth tends to improve network performances, it also makes gradient-based training more difficult since deeper networks tend to be more non-linear. The recently proposed knowledge distillation approach is aimed at obtaining small and fast-to-execute models, and it has shown that a student network could imitate the soft output of a larger teacher network or ensemble of networks. In this paper, we extend this idea to allow the training of a student that is deeper and thinner than the teacher, using not only the outputs but also the intermediate representations learned by the teacher as hints to improve the training process and final performance of the student. Because the student intermediate hidden layer will generally be smaller than the teacher's intermediate hidden layer, additional parameters are introduced to map the student hidden layer to the prediction of the teacher hidden layer. This allows one to train deeper students that can generalize better or run faster, a trade-off that is controlled by the chosen student capacity. For example, on CIFAR-10, a deep student network with almost 10.4 times less parameters outperforms a larger, state-of-the-art teacher network.",
            "references": [
                "355d44f53428b1ac4fb2ab468d593c720640e5bd",
                "ccf415df5a83b343dae261286d29a40e8b80e6c6",
                "523b12db4004b89284387f978c2af8ae0e79d54b",
                "0c908739fbff75f03469d13d4a1a07de3414ee19",
                "8978cf7574ceb35f4c3096be768c7547b28a35d0",
                "5d90f06bb70a0a3dced62413346235c02b1aa086",
                "021fc345d40d3e6332cd2ef276e2eaa5e71102e4",
                "184ac0766262312ba76bbdece4e7ffad0aa8180b",
                "eb42cf88027de515750f230b23b1a057dc782108",
                "e7bf9803705f2eb608db1e59e5c7636a3f171916"
            ]
        },
        {
            "id": "e15cf50aa89fee8535703b9f9512fca5bfc43327",
            "title": "Going deeper with convolutions",
            "authors": [
                "Christian Szegedy",
                "Wei Liu",
                "Yangqing Jia",
                "Pierre Sermanet",
                "Scott Reed",
                "Dragomir Anguelov",
                "Dumitru Erhan",
                "Vincent Vanhoucke",
                "Andrew Rabinovich"
            ],
            "date": "2015",
            "abstract": "We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.",
            "references": [
                "d67175d17c450ab0ac9c256103828f9e9a0acb85",
                "67fc0ec1d26f334b05fe66d2b7e0767b60fb73b6",
                "1109b663453e78a59e4f66446d71720ac58cec25",
                "1a2a770d23b4a171fa81de62a78a3deb0588f238",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "713f73ce5c3013d9fb796c21b981dc6629af0bd5",
                "a9ce496186120df8f9ed3367e76a4947419e992e",
                "3127190433230b3dc1abd0680bb58dced4bcd90e",
                "2a002ce457f7ab3088fbd2691734f1ce79f750c4"
            ]
        },
        {
            "id": "0c908739fbff75f03469d13d4a1a07de3414ee19",
            "title": "Distilling the Knowledge in a Neural Network",
            "authors": [
                "Geoffrey E. Hinton",
                "Oriol Vinyals",
                "Jeffrey Dean"
            ],
            "date": "2015",
            "abstract": "A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.",
            "references": [
                "34f25a8704614163c4095b3ee2fc969b60de4698",
                "8d25d04051074be7590cbe5e4e34c45bb26674e1",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "1366de5bb112746a555e9c0cd00de3ad8628aea8",
                "3127190433230b3dc1abd0680bb58dced4bcd90e",
                "30c9bb327b7f2b9f1d1e5b69b9d0c97b410948d9",
                "c8d90974c3f3b40fa05e322df2905fc16204aa56",
                "31868290adf1c000c611dfc966b514d5a34e8d23",
                "a0456c27cdd58f197032c1c8b4f304f09d4c9bc5"
            ]
        },
        {
            "id": "eb42cf88027de515750f230b23b1a057dc782108",
            "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
            "authors": [
                "Karen Simonyan",
                "Andrew Zisserman"
            ],
            "date": "2015",
            "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.",
            "references": [
                "14d9be7962a4ec5a6e55755f4c7588ea00793652",
                "d67175d17c450ab0ac9c256103828f9e9a0acb85",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "67dccc9a856b60bdc4d058d83657a089b8ad4486",
                "1109b663453e78a59e4f66446d71720ac58cec25",
                "39f3b1804b8df5be645a1dcb4a876e128385d9be",
                "6270baedeba28001cd1b563a199335720d6e0fe0",
                "dc6ac3437f0a6e64e4404b1b9d188394f8a3bf71",
                "398c296d0cc7f9d180f84969f8937e6d3a413796"
            ]
        },
        {
            "id": "e8650503ab80ad7299f0845b1843abf3a97f313a",
            "title": "Predicting Parameters in Deep Learning",
            "authors": [
                "Misha Denil",
                "Babak Shakibi",
                "Laurent Dinh",
                "Marc'Aurelio Ranzato",
                "Nando de Freitas"
            ],
            "date": "2013",
            "abstract": "We demonstrate that there is significant redundancy in the parameterization of several deep learning models. Given only a few weight values for each feature it is possible to accurately predict the remaining values. Moreover, we show that not only can the parameter values be predicted, but many of them need not be learned at all. We train several different architectures by learning only a small number of weights and predicting the rest. In the best case we are able to predict more than 95% of the weights of a network without any drop in accuracy.",
            "references": [
                "be9a17321537d9289875fe475b71f4821457b435",
                "72d32c986b47d6b880dad0c3f155fe23d2939038",
                "182015c5edff1956cbafbcb3e7bbe294aa54f9fc",
                "b7b915d508987b73b61eccd2b237e7ed099a2d29",
                "5352b7ca90cbe4938f8e71a25d49517e7f94670a",
                "72e93aa6767ee683de7f001fa72f1314e40a8f35",
                "51e93552fe55be91a5711ff2aabc04b742503e68",
                "3127190433230b3dc1abd0680bb58dced4bcd90e",
                "1366de5bb112746a555e9c0cd00de3ad8628aea8",
                "052b1d8ce63b07fec3de9dbb583772d860b7c769"
            ]
        },
        {
            "id": "327d3df8ea2020882827d6bace1e26c9d24309c2",
            "title": "The dropout learning algorithm",
            "authors": [
                "Pierre Baldi",
                "Peter Sadowski"
            ],
            "date": "2014",
            "abstract": "Dropout is a recently introduced algorithm for training neural network by randomly dropping units during training to prevent their co-adaptation. A mathematical analysis of some of the static and dynamic properties of dropout is provided using Bernoulli gating variables, general enough to accommodate dropout on units or connections, and with variable rates. The framework allows a complete analysis of the ensemble averaging properties of dropout in linear networks, which is useful to understand the non-linear case. The ensemble averaging properties of dropout in non-linear logistic networks result from three fundamental equations: (1) the approximation of the expectations of logistic functions by normalized geometric means, for which bounds and estimates are derived; (2) the algebraic equality between normalized geometric means of logistic functions with the logistic of the means, which mathematically characterizes logistic functions; and (3) the linearity of the means with respect to sums, as well as products of independent variables. The results are also extended to other classes of transfer functions, including rectified linear functions. Approximation errors tend to cancel each other and do not accumulate. Dropout can also be connected to stochastic neurons and used to predict firing rates, and to backpropagation by viewing the backward propagation as ensemble averaging in a dropout linear network. Moreover, the convergence properties of dropout can be understood in terms of stochastic gradient descent. Finally, for the regularization properties of dropout, the expectation of the dropout gradient is the gradient of the corresponding approximation ensemble, regularized by an adaptive weight decay term with a propensity for self-consistent variance minimization and sparse representations.",
            "references": [
                "cc46229a7c47f485e090857cbab6e6bf68c09811",
                "f9f19bee621faf46f90b023f8de8248b57becbc4",
                "ec92efde21707ddf4b81f301cd58e2051c1a2443",
                "d124a098cdc6f99b9a152fcf8afa9327dac583be",
                "87c4eca6aceb29557f693fdc4efc1fbff003e02a",
                "f8d37cf4c4a2f15acd7c6ab2b4b4f25a3f3d7f9c",
                "7826ff60d2dfb24d2af18c5bc565c357ef9db4c1",
                "c3ecd8e19e016d15670c8953b4b9afaa5186b0f3",
                "3c20df69865df6a627cc45c524869ccc0297048f",
                "052b1d8ce63b07fec3de9dbb583772d860b7c769"
            ]
        },
        {
            "id": "7b0db6135b8dd3e2a9efa86163e91c0cd0fdf660",
            "title": "Stochastic Learning",
            "authors": [
                "L{\\'e}on Bottou"
            ],
            "date": "2003",
            "abstract": "This contribution presents an overview of the theoretical and practical aspects of the broad family of learning algorithms based on Stochastic Gradient Descent, including Perceptrons, Adalines, K-Means, LVQ, Multi-Layer Networks, and Graph Transformer Networks.",
            "references": [
                "8213dbed4db44e113af3ed17d6dad57471a0c048",
                "111fd833a4ae576cfdbb27d87d2f8fc0640af355",
                "133809cf62bf67f0a63b35e5ef5180d20c9aec19",
                "2352d9105de31032538900dfb2ce7c95f6402963",
                "edbb1433410479a21eca006e9baff24fb846c132",
                "3380f30e85577f67f7e178b70bf9f120ec16a3bc",
                "bb587e7ddd3647f87e3b81675461f04284a3b261",
                "fc6b1ff29f2da985cccfa644652bb320d7720d59",
                "9df0be142d96fb454d6d863a76dc9e0448cc8428",
                "a8e8f3c8d4418c8d62e306538c9c1292635e9d27"
            ]
        },
        {
            "id": "1366de5bb112746a555e9c0cd00de3ad8628aea8",
            "title": "Improving neural networks by preventing co-adaptation of feature detectors",
            "authors": [
                "Geoffrey E. Hinton",
                "Nitish Srivastava",
                "Alex Krizhevsky",
                "Ilya Sutskever",
                "Ruslan Salakhutdinov"
            ],
            "date": "2012",
            "abstract": "When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This \"overfitting\" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random \"dropout\" gives big improvements on many benchmark tasks and sets new records for speech and object recognition.",
            "references": [
                "5d90f06bb70a0a3dced62413346235c02b1aa086",
                "db869fa192a3222ae4f2d766674a378e47013b1b",
                "d779f5c56a7121bdb62d73c1894a1ab0d182cbc2",
                "950bb724db08b009e6305157ac21b484cd2771fe"
            ]
        },
        {
            "id": "0688fbcbfb08d7b91238bc90589209b31f97290f",
            "title": "A CONVERGENCE THEOREM FOR NON NEGATIVE ALMOST SUPERMARTINGALES AND SOME APPLICATIONS",
            "authors": [
                "Herbert Robbins",
                "David Siegmund"
            ],
            "date": "1985",
            "abstract": "The purpose of this paper is to give a unified treatment of a number of almost sure convergence theorems by exploiting the fact that the processes involved possess a common \u201calmost supermartingale\u201d properties To be precise, let (\u03a9,F,P) be a probability space and F1 \u2282 F2 \u2282 \u2026 a sequence of sub-\u03c3-algebras of F. For each n= 1,2, \u2026 let zn, \u03b2n, \u03ben, and \u03b6n be non-negative Fn -measurable random variables such that \n \n$$E({z_{n + 1}}|{F_n}) \\leqslant {z_n}(1 + {\\beta _n}) + {\\xi _n} - {\\zeta _n}.$$ \n \n(1) \n \n.",
            "references": []
        },
        {
            "id": "7ab5ceb40c0e267ea6fcdbcaedd327d7b263bb8e",
            "title": "A refinement of the arithmetic mean-geometric mean inequality",
            "authors": [
                "Donald I. Cartwright",
                "Michael John Field"
            ],
            "date": "1978",
            "abstract": "Upper and lower bounds are given for the difference between the arithmetic and geometric means of n positive real numbers in terms of the variance of these numbers. In this note we prove a simple refinement of the arithmetic mean-geometric mean inequality. Our result solves a problem posed by Kenneth S. Williams in [5] and generalizes an inequality on p. 215 of [3]. Other estimates for the difference between the means are discussed in [2], [3] and [4]. THEOREM. Suppose that Xk E [a, b] and Pk > 0 for k = 1, ... , n, where a > 0, and suppose that ,-lPk = 1. Then, writing x = E4=ipkxk, we have 2 Pk(Xk x)2X I (Xkp) 0, and let yt = fb t dm(t) and a2 f= b(t -_ [)2 dm(t) be the mean and variance of m. Then 2b a2 < exp(( log(t) dm(t)) 2< a2 This follows from our theorem and the weak* density of the measures of the form En lPk6kx (where 6x denotes the probability measure which is concentrated at the point x) in the set of all probability measures on [a, b]. (See [1, p. 709].) Notice that the inequality /b expt log(t) dm (t) < tt Received by the editors August 15, 1977. AMS (MOS) subject classifications (1970). Primary 26A87.",
            "references": [
                "d6f7057c714a972f4b7b6130b1c44bfab750c560",
                "827347d6dc00fca9a4cef8ebc03663a8cb0da91a"
            ]
        },
        {
            "id": "ba15f09796d53adfbe9e78cf79182e59b6045543",
            "title": "On the Ky Fan inequality and related inequalities II",
            "authors": [
                "Edward Neuman",
                "J{\\'o}zsef S{\\'a}ndor"
            ],
            "date": "2005",
            "abstract": "Disclosed is an information processing apparatus including a display unit displaying information on a display screen, an operation unit including a text input key, and a control unit. The control unit displays text in response to input from the operation unit in a state of displaying an initial screen on the display screen, shows an application using text to a user for selection, starts up the application in accordance with the user's selection, and executes the application, using the text inputted from the operation unit.",
            "references": [
                "718b1ccd4a794207dd12c0264042a12a7d4e7797",
                "a419456b897eb646d5c9b8f075ffd9d283fff26e",
                "8861a5a674c2a6c06f781095bd1c15811a16be01",
                "6d02ef4ef79f3cb57dcf4eb20f890aa1be859219",
                "a1ea19d292460e3b7fca3df1313482f5abc0897e",
                "7b0b4826a3919f4a1a5559d4dba68c515fb95d3a",
                "a211a693915981acea30e9360b11e055baed8299",
                "94fae0f11be9f67bc6818553e10599ced559422d",
                "1295e0ec83fa4e5efbbfaf156d8525fdc8907929",
                "ed16d9f71c3b5db08b95abf6e2800e7af6179f08"
            ]
        },
        {
            "id": "fc6b1ff29f2da985cccfa644652bb320d7720d59",
            "title": "Online Algorithms and Stochastic Approximations",
            "authors": [
                "L{\\'e}on Bottou"
            ],
            "date": "1998",
            "abstract": "A process for the liquid phase oxidation of hydrocarbons with a molecular oxygen-containing gas in the presence of a dissolved cobalt salt catalyst characterized in that the oxidation is carried out in the substantial absence of chromium in the reaction medium i.e. a concentration of chromium in the liquid phase of not greater than 400 ppm.",
            "references": []
        },
        {
            "id": "a6373454105df0c5511ca5f6cae4d20c48214272",
            "title": "Fixed point optimization of deep convolutional neural networks for object recognition",
            "authors": [
                "Sajid Anwar",
                "Kyuyeon Hwang",
                "Wonyong Sung"
            ],
            "date": "2015",
            "abstract": "Deep convolutional neural networks have shown promising results in image and speech recognition applications. The learning capability of the network improves with increasing depth and size of each layer. However this capability comes at the cost of increased computational complexity. Thus reduction in hardware complexity and faster classification are highly desired. This work proposes an optimization method for fixed point deep convolutional neural networks. The parameters of a pre-trained high precision network are first directly quantized using L2 error minimization. We quantize each layer one by one, while other layers keep computation with high precision, to know the layer-wise sensitivity on word-length reduction. Then the network is retrained with quantized weights. Two examples on object recognition, MNIST and CIFAR-10, are presented. Our results indicate that quantization induces sparsity in the network which reduces the effective number of network parameters and improves generalization. This work reduces the required memory storage by a factor of 1/10 and achieves better classification results than the high precision networks.",
            "references": [
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "a4db2d26b5d169de6b64de361dc7d4fd5b1f61a3",
                "5d21006fa32ff69f6b0a646f26ce0db84f2f4d33",
                "e277762804aa4615b2258fbd367d91326c00b90e",
                "162d958ff885f1462aeda91cd72582323fd6a1f4",
                "5d90f06bb70a0a3dced62413346235c02b1aa086",
                "5562a56da3a96dae82add7de705e2bd841eb00fc",
                "c3c82b476162d2d006e02180530875a64af18154",
                "0abb49fe138e8fb7332c26b148a48d0db39724fc"
            ]
        },
        {
            "id": "efb5032e6199c80f83309fd866b25be9545831fd",
            "title": "Compressing Neural Networks with the Hashing Trick",
            "authors": [
                "Wenlin Chen",
                "James T. Wilson",
                "Stephen Tyree",
                "Kilian Q. Weinberger",
                "Yixin Chen"
            ],
            "date": "2015",
            "abstract": "As deep nets are increasingly used in applications suited for mobile devices, a fundamental dilemma becomes apparent: the trend in deep learning is to grow models to absorb ever-increasing data set sizes; however mobile devices are designed with very little memory and cannot store such large models. We present a novel network architecture, HashedNets, that exploits inherent redundancy in neural networks to achieve drastic reductions in model sizes. HashedNets uses a low-cost hash function to randomly group connection weights into hash buckets, and all connections within the same hash bucket share a single parameter value. These parameters are tuned to adjust to the HashedNets weight sharing architecture with standard backprop during training. Our hashing procedure introduces no additional memory overhead, and we demonstrate on several benchmark data sets that HashedNets shrink the storage requirements of neural networks substantially while mostly preserving generalization performance.",
            "references": [
                "b7cf49e30355633af2db19f35189410c8515e91f",
                "851c27d7cdb74b0b21bd84a9333bca106f486713",
                "d1208ac421cf8ff67b27d93cd19ae42b8d596f95",
                "be9a17321537d9289875fe475b71f4821457b435",
                "e5ae8ab688051931b4814f6d32b18391f8d1fa8d",
                "72e93aa6767ee683de7f001fa72f1314e40a8f35",
                "7a6fd5573d2679506765d461ec4892fd4017b745",
                "34f25a8704614163c4095b3ee2fc969b60de4698",
                "82b9099ddf092463f497bd48bb112c46ca52c4d1",
                "41fef1a197fab9684a4608b725d3ae72e1ab4b39"
            ]
        },
        {
            "id": "27a99c21a1324f087b2f144adc119f04137dfd87",
            "title": "Deep Fried Convnets",
            "authors": [
                "Zichao Yang",
                "Marcin Moczulski",
                "Misha Denil",
                "Nando de Freitas",
                "Alexander J. Smola",
                "Le Song",
                "Ziyu Wang"
            ],
            "date": "2015",
            "abstract": "The fully-connected layers of deep convolutional neural networks typically contain over 90% of the network parameters. Reducing the number of parameters while preserving predictive performance is critically important for training big models in distributed systems and for deployment in embedded devices. In this paper, we introduce a novel Adaptive Fastfood transform to reparameterize the matrix-vector multiplication of fully connected layers. Reparameterizing a fully connected layer with d inputs and n outputs with the Adaptive Fastfood transform reduces the storage and computational costs costs from O(nd) to O(n) and O(n log d) respectively. Using the Adaptive Fastfood transform in convolutional networks results in what we call a deep fried convnet. These convnets are end-to-end trainable, and enable us to attain substantial reductions in the number of parameters without affecting prediction accuracy on the MNIST and ImageNet datasets.",
            "references": [
                "2a4117849c88d4728c33b1becaa9fb6ed7030725",
                "e7bf9803705f2eb608db1e59e5c7636a3f171916",
                "5e83ab70d0cbc003471e87ec306d27d9c80ecb16",
                "6fe78db480995464bd97ba3b712ecc82129e6179",
                "e15cf50aa89fee8535703b9f9512fca5bfc43327",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "081651b38ff7533550a3adfc1c00da333a8fe86c",
                "6bdb186ec4726e00a8051119636d4df3b94043b5",
                "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff"
            ]
        },
        {
            "id": "6bdb186ec4726e00a8051119636d4df3b94043b5",
            "title": "Caffe: Convolutional Architecture for Fast Feature Embedding",
            "authors": [
                "Yangqing Jia",
                "Evan Shelhamer",
                "Jeff Donahue",
                "Sergey Karayev",
                "Jonathan Long",
                "Ross B. Girshick",
                "Sergio Guadarrama",
                "Trevor Darrell"
            ],
            "date": "2014",
            "abstract": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments.\n Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects, large-scale industrial applications, and startup prototypes in vision, speech, and multimedia.",
            "references": []
        },
        {
            "id": "d7bfd8a283a7ed8b43255cfd04909484cd3ade28",
            "title": "Efficient Sampling for k-Determinantal Point Processes",
            "authors": [
                "Chengtao Li",
                "Stefanie Jegelka",
                "Suvrit Sra"
            ],
            "date": "2016",
            "abstract": "Determinantal Point Processes (DPPs) are elegant probabilistic models of repulsion and diversity over discrete sets of items. But their applicability to large sets is hindered by expensive cubic-complexity matrix operations for basic tasks such as sampling. In light of this, we propose a new method for approximate sampling from discrete $k$-DPPs. Our method takes advantage of the diversity property of subsets sampled from a DPP, and proceeds in two stages: first it constructs coresets for the ground set of items; thereafter, it efficiently samples subsets based on the constructed coresets. As opposed to previous approaches, our algorithm aims to minimize the total variation distance to the original distribution. Experiments on both synthetic and real datasets indicate that our sampling algorithm works efficiently on large data sets, and yields more accurate samples than previous approaches.",
            "references": [
                "8ba555d9587688bd3225d71ef9d686dad288e1f1",
                "551fcb42b7feb047f5405777e17658538785b679",
                "ec46bcbced500820521e9f65b0f9ffef5a83ae11",
                "3dd88e27a6d0df463c6a112be97f328850c13fff",
                "15acca25f75076b80b0bd24c5710c70733308c11",
                "19c205a19296ec0e940fe1680e265861d6701a90",
                "a13d1abfd5594cc8067abc4f6c095ad0ca1c2a88",
                "492fe08ffda79123b34690f5493801129e88f2b7",
                "48a17d25d76f9bdf90fdd86d2b3e2739e5bb8016",
                "50e81b362683ec056a203e9ffa86b243e920e630"
            ]
        },
        {
            "id": "87d810fcea61068e8b29f2b75fa1cbb00c190bea",
            "title": "Reshaping deep neural network for fast decoding by node-pruning",
            "authors": [
                "Tianxing He",
                "Yuchen Fan",
                "Yanmin Qian",
                "Tian Tan",
                "Kai Yu"
            ],
            "date": "2014",
            "abstract": "Although deep neural networks (DNN) has achieved significant accuracy improvements in speech recognition, it is computationally expensive to deploy large-scale DNN in decoding due to huge number of parameters. Weights truncation and decomposition methods have been proposed to speed up decoding by exploiting the sparseness of DNN. This paper summarizes different approaches of restructuring DNN and proposes a new node pruning approach to reshape DNN for fast decoding. In this approach, hidden nodes of a fully trained DNN are pruned with certain importance function and the reshaped DNN is retuned using back-propagation. The approach requires no modification on code and can directly save computational costs during decoding. Furthermore, it is complementary to weight decomposition methods. Experiments on a switchboard task shows that, by using the proposed node-pruning approach, DNN complexity can be reduced to 37.9%. The complexity can be further reduced to 12.3% without accuracy loss when node-pruning is combined with weight decomposition.",
            "references": [
                "6d9429b96d9bb40e2d0d9c3f57d0b97f61db8503",
                "1c2c11e60755fc1df95f57edc37875e2b43cd946",
                "5cea23330c76994cb626df20bed31cc2588033df",
                "d0191c9b53a99942a9b4ec39dc30489e41c7aaa1",
                "fbeaa499e10e98515f7e1c4ad89165e8c0677427",
                "6658bbf68995731b2083195054ff45b4eca38b3a",
                "8d52f379250a9755f463a9f1a86d555341329001",
                "077b54784ffc0fc4b335392a0bdf630f595a12ce",
                "e354ec85b8287bf15ed596be16ef6e422ccc29e7",
                "d2b62f77cb2864e465aa60bca6c26bb1d2f84963"
            ]
        },
        {
            "id": "48a17d25d76f9bdf90fdd86d2b3e2739e5bb8016",
            "title": "Determinantal Point Processes for Machine Learning",
            "authors": [
                "Alex Kulesza",
                "Ben Taskar"
            ],
            "date": "2012",
            "abstract": "Determinantal point processes (DPPs) are elegant probabilistic models of repulsion that arise in quantum physics and random matrix theory. In contrast to traditional structured models like Markov random fields, which become intractable and hard to approximate in the presence of negative correlations, DPPs offer efficient and exact algorithms for sampling, marginalization, conditioning, and other inference tasks. While they have been studied extensively by mathematicians, giving rise to a deep and beautiful theory, DPPs are relatively new in machine learning. Determinantal Point Processes for Machine Learning provides a comprehensible introduction to DPPs, focusing on the intuitions, algorithms, and extensions that are most relevant to the machine learning community, and shows how DPPs can be applied to real-world applications like finding diverse sets of high-quality search results, building informative summaries by selecting diverse sentences from documents, modeling non-overlapping human poses in images or video, and automatically building timelines of important news stories. It presents the general mathematical background to DPPs along with a range of modeling extensions, efficient algorithms, and theoretical results that aim to enable practical modeling and learning.",
            "references": [
                "15acca25f75076b80b0bd24c5710c70733308c11",
                "ec46bcbced500820521e9f65b0f9ffef5a83ae11",
                "c87f5836627a4ea7d928ff1aecf1b7cdebaf1302",
                "6c4ab2b7bf202e621dcb722d2e7cf421415cc3ed",
                "733edbe153056edb62f3c3cdec975db85a072906",
                "702c2fde33ccb4328be06405c11e208a4b3ee347",
                "325ea1f2022ee3886a5810df76dcfbe4010ad439",
                "96a5867d0b9b997108633ff3da314edf69b0122c",
                "e0ab5b00d4fb0ef319093f94d5024008b6000381",
                "b91afd46236a9c9eda9056bf4e70fe9235867571"
            ]
        },
        {
            "id": "ec46bcbced500820521e9f65b0f9ffef5a83ae11",
            "title": "k-DPPs: Fixed-Size Determinantal Point Processes",
            "authors": [
                "Alex Kulesza",
                "Ben Taskar"
            ],
            "date": "2011",
            "abstract": "Determinantal point processes (DPPs) have recently been proposed as models for set selection problems where diversity is preferred. For example, they can be used to select diverse sets of sentences to form document summaries, or to find multiple non-overlapping human poses in an image. However, DPPs conflate the modeling of two distinct characteristics: the size of the set, and its content. For many realistic tasks, the size of the desired set is known up front; e.g., in search we may want to show the user exactly ten results. In these situations the effort spent by DPPs modeling set size is not only wasteful, but actually introduces unwanted bias into the modeling of content. Instead, we propose the k-DPP, a conditional DPP that models only sets of cardinality k. In exchange for this restriction, k-DPPs offer greater expressiveness and control over content, and simplified integration into applications like search. We derive algorithms for efficiently normalizing, sampling, and marginalizing k-DPPs, and propose an experts-style algorithm for learning combinations of k-DPPs. We demonstrate the usefulness of the model on an image search task, where k-DPPs significantly outperform MMR as judged by human annotators.",
            "references": [
                "6c4ab2b7bf202e621dcb722d2e7cf421415cc3ed",
                "ddbf1f0ff1f720ccff489806b16c56d8124470e3",
                "5f10ce4992742b7134d146d91af6a66077140f5f",
                "fabe20a21465511a1d56d319e52eec17005b3452",
                "a22ac183c8b37824e32cae970db170b861a13438",
                "b91afd46236a9c9eda9056bf4e70fe9235867571",
                "1840c15f0ce85a7f4756c185cd29508d6b53c66c",
                "ce72362402738b024c0ba7919c3a89c07b8d66d2",
                "f9f836d28f52ad260213d32224a6d227f8e8849a",
                "9d94fc289d82738a4d1071470b16ba861ea12169"
            ]
        },
        {
            "id": "a42954d4b9d0ccdf1036e0af46d87a01b94c3516",
            "title": "Second Order Derivatives for Network Pruning: Optimal Brain Surgeon",
            "authors": [
                "Babak Hassibi",
                "David G. Stork"
            ],
            "date": "1992",
            "abstract": "We investigate the use of information from all second order derivatives of the error function to perform network pruning (i.e., removing unimportant weights from a trained network) in order to improve generalization, simplify networks, reduce hardware or storage requirements, increase the speed of further training, and in some cases enable rule extraction. Our method, Optimal Brain Surgeon (OBS), is Significantly better than magnitude-based methods and Optimal Brain Damage [Le Cun, Denker and Solla, 1990], which often remove the wrong weights. OBS permits the pruning of more weights than other methods (for the same error on the training set), and thus yields better generalization on test data. Crucial to OBS is a recursion relation for calculating the inverse Hessian matrix H-1 from training data and structural information of the net. OBS permits a 90%, a 76%, and a 62% reduction in weights over backpropagation with weight decay on three benchmark MONK's problems [Thrun et al., 1991]. Of OBS, Optimal Brain Damage, and magnitude-based methods, only OBS deletes the correct weights from a trained XOR network in every case. Finally, whereas Sejnowski and Rosenberg [1987] used 18,000 weights in their NETtalk network, we used OBS to prune a network to just 1560 weights, yielding better generalization.",
            "references": [
                "e8eaf8aedb495b6ae0e174eea11e3cfcdf4a3724",
                "e7297db245c3feb1897720b173a59fe7e36babb7",
                "de996c32045df6f7b404dda2a753b6a9becf3c08",
                "5887de8eed53c444b2ef93d8ab9c8cc685cd7ac5",
                "1b29884885401d12299a01b0eae099f425dd32e1",
                "6c0cbbd275bb43e09f0527a31ddd61824eca295b",
                "d382b9c11e5c6a8e173fbeb442545e3be8d3e3a5",
                "111fd833a4ae576cfdbb27d87d2f8fc0640af355"
            ]
        },
        {
            "id": "31f88db95eb5c66b95cd7335b0cd4f27f0f271f2",
            "title": "A Determinantal Point Process Latent Variable Model for Inhibition in Neural Spiking Data",
            "authors": [
                "Jasper Snoek",
                "Richard S. Zemel",
                "Ryan P. Adams"
            ],
            "date": "2013",
            "abstract": "Point processes are popular models of neural spiking behavior as they provide a statistical distribution over temporal sequences of spikes and help to reveal the complexities underlying a series of recorded action potentials. However, the most common neural point process models, the Poisson process and the gamma renewal process, do not capture interactions and correlations that are critical to modeling populations of neurons. We develop a novel model based on a determinantal point process over latent embeddings of neurons that effectively captures and helps visualize complex inhibitory and competitive interaction. We show that this model is a natural extension of the popular generalized linear model to sets of interacting neurons. The model is extended to incorporate gain control or divisive normalization, and the modulation of neural spiking based on periodic phenomena. Applied to neural spike recordings from the rat hippocampus, we see that the model captures inhibitory relationships, a dichotomy of classes of neurons, and a periodic modulation by the theta rhythm known to be present in the data.",
            "references": [
                "c76d84d779e28e3b236054a0f34c3e48910399d8",
                "0d92ce89894d50af18c902e6b89f85eb0d4fcde2",
                "2fbeef5ca17328590cf74353ff5654dad7800d67",
                "ef7bb077881079f686715e2de711b905f6a18829",
                "f46b5134322400e0b80e65cd2d308c982adfdc43",
                "eb84341018bc6e5775815a37c74876e1e5a1e5fb",
                "935e580d058c78cf8f1c08e3885254015c153089",
                "59d435c69a34efec487447c52f37cb96b36df570",
                "3e568fb5a3ce754abe9f029aa80610f16b9f9f92",
                "621fce5ca4d2480276f27567a9377c56766de048"
            ]
        },
        {
            "id": "8ba555d9587688bd3225d71ef9d686dad288e1f1",
            "title": "Fast Determinantal Point Process Sampling with Application to Clustering",
            "authors": [
                "Byungkon Kang"
            ],
            "date": "2013",
            "abstract": "Determinantal Point Process (DPP) has gained much popularity for modeling sets of diverse items. The gist of DPP is that the probability of choosing a particular set of items is proportional to the determinant of a positive definite matrix that defines the similarity of those items. However, computing the determinant requires time cubic in the number of items, and is hence impractical for large sets. In this paper, we address this problem by constructing a rapidly mixing Markov chain, from which we can acquire a sample from the given DPP in sub-cubic time. In addition, we show that this framework can be extended to sampling from cardinality-constrained DPPs. As an application, we show how our sampling algorithm can be used to provide a fast heuristic for determining the number of clusters, resulting in better clustering.",
            "references": [
                "15acca25f75076b80b0bd24c5710c70733308c11",
                "ec46bcbced500820521e9f65b0f9ffef5a83ae11",
                "48a17d25d76f9bdf90fdd86d2b3e2739e5bb8016",
                "c87f5836627a4ea7d928ff1aecf1b7cdebaf1302",
                "b91afd46236a9c9eda9056bf4e70fe9235867571",
                "2b5db2ef319226e1a019c10bd17af0c283b56cf7",
                "5c8fe9a0412a078e30eb7e5eeb0068655b673e86",
                "c02dfd94b11933093c797c362e2f8f6a3b9b8012",
                "8faad7901db9a73cacaf92ecdedbaece87d95f92",
                "d82bfe2f1a913670862de75b56ddd4649161b00b"
            ]
        },
        {
            "id": "60ae4f18cb53efff0174e3fea7064049737e1e67",
            "title": "Network Trimming: A Data-Driven Neuron Pruning Approach towards Efficient Deep Architectures",
            "authors": [
                "Hengyuan Hu",
                "Rui Peng",
                "Yu-Wing Tai",
                "Chi-Keung Tang"
            ],
            "date": "2016",
            "abstract": "State-of-the-art neural networks are getting deeper and wider. While their performance increases with the increasing number of layers and neurons, it is crucial to design an efficient deep architecture in order to reduce computational and memory costs. Designing an efficient neural network, however, is labor intensive requiring many experiments, and fine-tunings. In this paper, we introduce network trimming which iteratively optimizes the network by pruning unimportant neurons based on analysis of their outputs on a large dataset. Our algorithm is inspired by an observation that the outputs of a significant portion of neurons in a large network are mostly zero, regardless of what inputs the network received. These zero activation neurons are redundant, and can be removed without affecting the overall accuracy of the network. After pruning the zero activation neurons, we retrain the network using the weights before pruning as initialization. We alternate the pruning and retraining to further reduce zero activations in a network. Our experiments on the LeNet and VGG-16 show that we can achieve high compression ratio of parameters without losing or even achieving higher accuracy than the original network.",
            "references": [
                "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff",
                "642d0f49b7826adcf986616f4af77e736229990f",
                "5e83ab70d0cbc003471e87ec306d27d9c80ecb16",
                "e15cf50aa89fee8535703b9f9512fca5bfc43327",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "eb42cf88027de515750f230b23b1a057dc782108",
                "a42954d4b9d0ccdf1036e0af46d87a01b94c3516",
                "969fbdcd0717bec06228053788c2ff78bbb4daac",
                "424561d8585ff8ebce7d5d07de8dbf7aae5e7270"
            ]
        },
        {
            "id": "7601b995303f953955004db7b9b8b206c0e02ff8",
            "title": "Learning Structured Sparsity in Deep Neural Networks",
            "authors": [
                "Wei Wen",
                "Chunpeng Wu",
                "Yandan Wang",
                "Yiran Chen",
                "Hai Li"
            ],
            "date": "2016",
            "abstract": "High demand for computation resources severely hinders deployment of large-scale Deep Neural Networks (DNN) in resource constrained devices. In this work, we propose a Structured Sparsity Learning (SSL) method to regularize the structures (i.e., filters, channels, filter shapes, and layer depth) of DNNs. SSL can: (1) learn a compact structure from a bigger DNN to reduce computation cost; (2) obtain a hardware-friendly structured sparsity of DNN to efficiently accelerate the DNNs evaluation. Experimental results show that SSL achieves on average 5.1x and 3.1x speedups of convolutional layer computation of AlexNet against CPU and GPU, respectively, with off-the-shelf libraries. These speedups are about twice speedups of non-structured sparsity; (3) regularize the DNN structure to improve classification accuracy. The results show that for CIFAR-10, regularization on layer depth can reduce 20 layers of a Deep Residual Network (ResNet) to 18 layers while improve the accuracy from 91.25% to 92.60%, which is still slightly higher than that of original ResNet with 32 layers. For AlexNet, structure regularization by SSL also reduces the error by around ~1%. Open source code is in this https URL",
            "references": [
                "d559dd84fc473fca7e91b9075675750823935afa",
                "642d0f49b7826adcf986616f4af77e736229990f",
                "d5b4721c8188269b120d3d06149a04435753e755",
                "021fc345d40d3e6332cd2ef276e2eaa5e71102e4",
                "6cf7f474eb493b0e5aae74ccfd9cdc79e506060e",
                "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
                "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "e5ae8ab688051931b4814f6d32b18391f8d1fa8d"
            ]
        },
        {
            "id": "5887de8eed53c444b2ef93d8ab9c8cc685cd7ac5",
            "title": "A Frobenius approximation reduction method (FARM) for determining optimal number of hidden units",
            "authors": [
                "S. Kung",
                "Yu Hen Hu"
            ],
            "date": "1991",
            "abstract": "A least-square approximation method is proposed to reduce the number of hidden units of a trained multilayer perceptron artificial neural network structure. In this method, the hidden neurons that contribute the most to the net function of the output layer are retained while the hidden units that contribute the least are removed. It is shown theoretically that the proposed method minimizes the Frobenius norm of the approximation error, hence the name Frobenius approximation reduction method. Also reported are simulation results on ECG classifications. The results support the theoretical predictions arid yield very encouraging performances.<<ETX>>",
            "references": []
        },
        {
            "id": "e5ae8ab688051931b4814f6d32b18391f8d1fa8d",
            "title": "Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation",
            "authors": [
                "Emily L. Denton",
                "Wojciech Zaremba",
                "Joan Bruna",
                "Yann LeCun",
                "Rob Fergus"
            ],
            "date": "2014",
            "abstract": "We present techniques for speeding up the test-time evaluation of large convolutional networks, designed for object recognition tasks. These models deliver impressive accuracy, but each image evaluation requires millions of floating point operations, making their deployment on smartphones and Internet-scale clusters problematic. The computation is dominated by the convolution operations in the lower layers of the model. We exploit the redundancy present within the convolutional filters to derive approximations that significantly reduce the required computation. Using large state-of-the-art models, we demonstrate speedups of convolutional layers on both CPU and GPU by a factor of 2 x, while keeping the accuracy within 1% of the original model.",
            "references": [
                "021fc345d40d3e6332cd2ef276e2eaa5e71102e4",
                "a7621b4ec18719b08f3a2a444b6d37a2e20227b7",
                "1109b663453e78a59e4f66446d71720ac58cec25",
                "fbeaa499e10e98515f7e1c4ad89165e8c0677427",
                "d743430cb2329caa5d446c17fc9ec07f5e916ab0",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "05cc38e249a6f642363b5a5cbd71cda67cea5893",
                "72e93aa6767ee683de7f001fa72f1314e40a8f35",
                "e8650503ab80ad7299f0845b1843abf3a97f313a",
                "1366de5bb112746a555e9c0cd00de3ad8628aea8"
            ]
        },
        {
            "id": "1b29884885401d12299a01b0eae099f425dd32e1",
            "title": "Interpretation of Artificial Neural Networks: Mapping Knowledge-Based Neural Networks into Rules",
            "authors": [
                "Geoffrey G. Towell",
                "Jude W. Shavlik"
            ],
            "date": "1991",
            "abstract": "We propose and empirically evaluate a method for the extraction of expert-comprehensible rules from trained neural networks. Our method operates in the context of a three-step process for learning that uses rule-based domain knowledge in combination with neural networks. Empirical tests using real-worlds problems from molecular biology show that the rules our method extracts from trained neural networks: closely reproduce the accuracy of the network from which they came, are superior to the rules derived by a learning system that directly refines symbolic rules, and are expert-comprehensible.",
            "references": [
                "a080a28ff7fb3b58fa8cd7123a473c5e75bf46e1",
                "d2f6ac8b70044a437a7d5444252d6af6037b46c2",
                "a57c6d627ffc667ae3547073876c35d6420accff",
                "1e560e13357d180dda2507ef572961d9de913c6c",
                "fdfad550280c6a850d92424b6075e7fb58e8e415",
                "b981cb3324d69a079c8f934c67c1a8ce14358f17",
                "de75e4e15e22d4376300e5c968e2db44be29ac9e",
                "111fd833a4ae576cfdbb27d87d2f8fc0640af355",
                "d14670a0c65a007912b37e2436ee2d7caf70fd76",
                "d8c9a210221e3c925b4119a4ab90aa8b57bb31fc"
            ]
        },
        {
            "id": "de996c32045df6f7b404dda2a753b6a9becf3c08",
            "title": "Parallel Networks that Learn to Pronounce English Text",
            "authors": [
                "Terrence J. Sejnowski",
                "Charles R. Rosenberg"
            ],
            "date": "1987",
            "abstract": "This paper describes NETtalk, a class of massively-parallel network systems that learn to convert English text to speech. The memory representations for pronunciations are learned by practice and are shared among many processing units. The performance of NETtalk has some similarities with observed human performance. (i) The learning follows a power law. (ii) The more words the network learns, the better it is at generalizing and correctly pronouncing new words, (iii) The performance of the network degrades very slowly as connections in the network are damaged: no single link or processing unit is essential. (iv) Relearning after damage is much faster than learning during the original training. (v) Distributed or spaced practice is more effective for long-term retention than massed practice. Network models can be constructed that have the same performance and learning characteristics on a particular task, but differ completely at the levels of synaptic strengths and single-unit responses. However, hierarchical clustering techniques applied to NETtalk reveal that these different networks have similar internal representations of letter-to-sound correspondences within groups of processing units. This suggests that invariant internal representations may be found in assemblies of neurons intermediate in size between highly localized and completely distributed representations.",
            "references": [
                "dc298a55900b5149b69bbd7708342cc91ecc940d",
                "87d79c0c5255bce9dacaf4dab07d00c682200f2e",
                "ab4aec5e0714b352e6c90d063fe830cbc70912bc",
                "60944c5243db70a687a320a2622d3bd1610802a8",
                "84cdfa79e6eb9bf9e625e3af38d9f968df18a880",
                "bb407a5b0343e74ffb940845c23f7ca73eb7c067",
                "6b4fe4aa4d66fecc7b2869569002714d91d0b3f7",
                "4c51e3c0b4ed0f073d9bfd935b3a6824126336ab",
                "a1e33c9f79f993cc2f7d917d8cb6baee095c570d",
                "0cabc69aaf5dd7ff104bcec693a9ebe7bfb238c4"
            ]
        },
        {
            "id": "111fd833a4ae576cfdbb27d87d2f8fc0640af355",
            "title": "Learning internal representations by error propagation",
            "authors": [
                "David E. Rumelhart",
                "Geoffrey E. Hinton",
                "Ronald J. Williams"
            ],
            "date": "1986",
            "abstract": "This chapter contains sections titled: The Problem, The Generalized Delta Rule, Simulation Results, Some Further Generalizations, Conclusion",
            "references": [
                "97dee69f65955f5236befc40ab498c8ff524eef1",
                "14ad467038282291669442d962ae69deb64dd696",
                "0120eefaf05bfad5293e87f56d2e787c05f78cf7",
                "a0d16f0e99f7ce5e6fb70b1a68c685e9ad610657",
                "65974be9cb2d147e44f93ca0ca0ab5f4c9e22cd7",
                "84cdfa79e6eb9bf9e625e3af38d9f968df18a880",
                "bb4bad84a2fd896edfa4f5c22061b2913fec500d",
                "9db00dc5532e4c1b11404a6f957d806ca42c4e73",
                "08ebba9066b38e74ee8369ee1e47923ada0c355b",
                "69e68bfaadf2dccff800158749f5a50fe82d173b"
            ]
        },
        {
            "id": "57dc98cfb48247b400cc8decb93380e022864905",
            "title": "Introduction to the Theory of Neural Computation",
            "authors": [
                "John Hertz",
                "Anders Krogh",
                "Richard G. Palmer",
                "Roderick V. Jensen"
            ],
            "date": "1994",
            "abstract": "Semantic Scholar extracted view of \"Introduction to the Theory of Neural Computation\" by John Hertz et al.",
            "references": []
        },
        {
            "id": "7d39283a0fce1c96f57eb20046d09bd95ccc56d7",
            "title": "Structured Pruning of Deep Convolutional Neural Networks",
            "authors": [
                "Sajid Anwar",
                "Kyuyeon Hwang",
                "Wonyong Sung"
            ],
            "date": "2017",
            "abstract": "Real-time application of deep learning algorithms is often hindered by high computational complexity and frequent memory accesses. Network pruning is a promising technique to solve this problem. However, pruning usually results in irregular network connections that not only demand extra representation efforts but also do not fit well on parallel computation. We introduce structured sparsity at various scales for convolutional neural networks: feature map-wise, kernel-wise, and intra-kernel strided sparsity. This structured sparsity is very advantageous for direct computational resource savings on embedded computers, in parallel computing environments, and in hardware-based systems. To decide the importance of network connections and paths, the proposed method uses a particle filtering approach. The importance weight of each particle is assigned by assessing the misclassification rate with a corresponding connectivity pattern. The pruned network is retrained to compensate for the losses due to pruning. While implementing convolutions as matrix products, we particularly show that intra-kernel strided sparsity with a simple constraint can significantly reduce the size of the kernel and feature map tensors. The proposed work shows that when pruning granularities are applied in combination, we can prune the CIFAR-10 network by more than 70% with less than a 1% loss in accuracy.",
            "references": [
                "397de65a9a815ec39b3704a79341d687205bc80a",
                "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff",
                "2cc157afda51873c30b195fff56e917b9c06b853",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff"
            ]
        },
        {
            "id": "3ed94217fbf29b86d5f1baec90dc33adacb40b58",
            "title": "Less Is More: Towards Compact CNNs",
            "authors": [
                "Hao Zhou",
                "Jose M. Alvarez",
                "Fatih Murat Porikli"
            ],
            "date": "2016",
            "abstract": "To attain a favorable performance on large-scale datasets, convolutional neural networks (CNNs) are usually designed to have very high capacity involving millions of parameters. In this work, we aim at optimizing the number of neurons in a network, thus the number of parameters. We show that, by incorporating sparse constraints into the objective function, it is possible to decimate the number of neurons during the training stage. As a result, the number of parameters and the memory footprint of the neural network are also reduced, which is also desirable at the test time. We evaluated our method on several well-known CNN structures including AlexNet, and VGG over different datasets including ImageNet. Extensive experimental results demonstrate that our method leads to compact networks. Taking first fully connected layer as an example, our compact CNN contains only \\(30\\,\\%\\) of the original neurons without any degradation of the top-1 classification accuracy.",
            "references": [
                "2a4117849c88d4728c33b1becaa9fb6ed7030725",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "b0bd441a0cc04cdd0d0e469fe4c5184ee148a97d",
                "eb42cf88027de515750f230b23b1a057dc782108",
                "e7bf9803705f2eb608db1e59e5c7636a3f171916",
                "e6f2f3a5cc7c7213835b9aede15715b5830520e1",
                "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff",
                "021fc345d40d3e6332cd2ef276e2eaa5e71102e4",
                "d559dd84fc473fca7e91b9075675750823935afa"
            ]
        },
        {
            "id": "d559dd84fc473fca7e91b9075675750823935afa",
            "title": "Sparse Convolutional Neural Networks",
            "authors": [
                "Bao-Yuan Liu",
                "Meitian Wang",
                "Hassan Foroosh",
                "Marshall F. Tappen",
                "Marianna Pensky"
            ],
            "date": "2015",
            "abstract": "Deep neural networks have achieved remarkable performance in both image classification and object detection problems, at the cost of a large number of parameters and computational complexity. In this work, we show how to reduce the redundancy in these parameters using a sparse decomposition. Maximum sparsity is obtained by exploiting both inter-channel and intra-channel redundancy, with a fine-tuning step that minimize the recognition loss caused by maximizing sparsity. This procedure zeros out more than 90% of parameters, with a drop of accuracy that is less than 1% on the ILSVRC2012 dataset. We also propose an efficient sparse matrix multiplication algorithm on CPU for Sparse Convolutional Neural Networks (SCNN) models. Our CPU implementation demonstrates much higher efficiency than the off-the-shelf sparse matrix libraries, with a significant speedup realized over the original dense network. In addition, we apply the SCNN model to the object detection problem, in conjunction with a cascade model and sparse fully connected layers, to achieve significant speedups.",
            "references": [
                "021fc345d40d3e6332cd2ef276e2eaa5e71102e4",
                "eb42cf88027de515750f230b23b1a057dc782108",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "a7621b4ec18719b08f3a2a444b6d37a2e20227b7",
                "e5ae8ab688051931b4814f6d32b18391f8d1fa8d",
                "a9ce496186120df8f9ed3367e76a4947419e992e",
                "fbeaa499e10e98515f7e1c4ad89165e8c0677427",
                "cbb19236820a96038d000dc629225d36e0b6294a",
                "6bdb186ec4726e00a8051119636d4df3b94043b5"
            ]
        },
        {
            "id": "d5b4721c8188269b120d3d06149a04435753e755",
            "title": "Convolutional neural networks with low-rank regularization",
            "authors": [
                "Cheng Tai",
                "Tong Xiao",
                "Xiaogang Wang",
                "E Weinan"
            ],
            "date": "2016",
            "abstract": "Large CNNs have delivered impressive performance in various computer vision applications. But the storage and computation requirements make it problematic for deploying these models on mobile devices. Recently, tensor decompositions have been used for speeding up CNNs. In this paper, we further develop the tensor decomposition technique. We propose a new algorithm for computing the low-rank tensor decomposition for removing the redundancy in the convolution kernels. The algorithm finds the exact global optimizer of the decomposition and is more effective than iterative methods. Based on the decomposition, we further propose a new method for training low-rank constrained CNNs from scratch. Interestingly, while achieving a significant speedup, sometimes the low-rank constrained CNNs delivers significantly better performance than their non-constrained counterparts. On the CIFAR-10 dataset, the proposed low-rank NIN model achieves $91.31\\%$ accuracy (without data augmentation), which also improves upon state-of-the-art result. We evaluated the proposed method on CIFAR-10 and ILSVRC12 datasets for a variety of modern CNNs, including AlexNet, NIN, VGG and GoogleNet with success. For example, the forward time of VGG-16 is reduced by half while the performance is still comparable. Empirical success suggests that low-rank tensor decompositions can be a very useful tool for speeding up large CNNs.",
            "references": [
                "62e348e26976c3ef77909b9af9788ebc2509009a",
                "021fc345d40d3e6332cd2ef276e2eaa5e71102e4",
                "eb42cf88027de515750f230b23b1a057dc782108",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "e5ae8ab688051931b4814f6d32b18391f8d1fa8d",
                "e6f2f3a5cc7c7213835b9aede15715b5830520e1",
                "6bdb186ec4726e00a8051119636d4df3b94043b5",
                "e15cf50aa89fee8535703b9f9512fca5bfc43327",
                "9716e4f69040f3f182714d7fb16ab9a65fb34ba6"
            ]
        },
        {
            "id": "021fc345d40d3e6332cd2ef276e2eaa5e71102e4",
            "title": "Speeding up Convolutional Neural Networks with Low Rank Expansions",
            "authors": [
                "Max Jaderberg",
                "Andrea Vedaldi",
                "Andrew Zisserman"
            ],
            "date": "2014",
            "abstract": "The focus of this paper is speeding up the application of convolutional neural networks. While delivering impressive results across a range of computer vision and machine learning tasks, these networks are computationally demanding, limiting their deployability. Convolutional layers generally consume the bulk of the processing time, and so in this work we present two simple schemes for drastically speeding up these layers. This is achieved by exploiting cross-channel or filter redundancy to construct a low rank basis of filters that are rank-1 in the spatial domain. Our methods are architecture agnostic, and can be easily applied to existing CPU and GPU convolutional frameworks for tuneable speedup performance. We demonstrate this with a real world network designed for scene text character recognition [15], showing a possible 2.5\u00d7 speedup with no loss in accuracy, and 4.5\u00d7 speedup with less than 1% drop in accuracy, still achieving state-of-the-art on standard benchmarks.",
            "references": [
                "e5ae8ab688051931b4814f6d32b18391f8d1fa8d",
                "a7621b4ec18719b08f3a2a444b6d37a2e20227b7",
                "fbeaa499e10e98515f7e1c4ad89165e8c0677427",
                "4dbc68cf2e14155edb6da0def30661aca8c96c22",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "c08f5fa876181fc040d76c75fe2433eee3c9b001",
                "8b25a44f617c1ed3ed52c6655b0d456ff1c565bd",
                "1e80f755bcbf10479afd2338cec05211fdbd325c",
                "b3d8dffb73bc93de239998548386c84177caa2ad"
            ]
        },
        {
            "id": "8ad35df17ae4064dd174690efb04d347428f1117",
            "title": "Convolutional neural networks at constrained time cost",
            "authors": [
                "Kaiming He",
                "Jian Sun"
            ],
            "date": "2015",
            "abstract": "Though recent advanced convolutional neural networks (CNNs) have been improving the image recognition accuracy, the models are getting more complex and time-consuming. For real-world applications in industrial and commercial scenarios, engineers and developers are often faced with the requirement of constrained time budget. In this paper, we investigate the accuracy of CNNs under constrained time cost. Under this constraint, the designs of the network architectures should exhibit as trade-offs among the factors like depth, numbers of filters, filter sizes, etc. With a series of controlled comparisons, we progressively modify a baseline model while preserving its time complexity. This is also helpful for understanding the importance of the factors in network designs. We present an architecture that achieves very competitive accuracy in the ImageNet dataset (11.8% top-5 error, 10-view test), yet is 20% faster than \u201cAlexNet\u201d [14] (16.0% top-5 error, 10-view test).",
            "references": [
                "021fc345d40d3e6332cd2ef276e2eaa5e71102e4",
                "14d9be7962a4ec5a6e55755f4c7588ea00793652",
                "eb42cf88027de515750f230b23b1a057dc782108",
                "cbb19236820a96038d000dc629225d36e0b6294a",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "e15cf50aa89fee8535703b9f9512fca5bfc43327",
                "e5ae8ab688051931b4814f6d32b18391f8d1fa8d",
                "6270baedeba28001cd1b563a199335720d6e0fe0",
                "d67175d17c450ab0ac9c256103828f9e9a0acb85"
            ]
        },
        {
            "id": "751c8884c1e857e675d85d8594c5f9b608005ed5",
            "title": "Training CNNs with Low-Rank Filters for Efficient Image Classification",
            "authors": [
                "Yani A Ioannou",
                "Duncan P. Robertson",
                "Jamie Shotton",
                "Roberto Cipolla",
                "Antonio Criminisi"
            ],
            "date": "2016",
            "abstract": "We propose a new method for creating computationally efficient convolutional neural networks (CNNs) by using low-rank representations of convolutional filters. Rather than approximating filters in previously-trained networks with more efficient versions, we learn a set of small basis filters from scratch; during training, the network learns to combine these basis filters into more complex filters that are discriminative for image classification. To train such networks, a novel weight initialization scheme is used. This allows effective initialization of connection weights in convolutional layers composed of groups of differently-shaped filters. We validate our approach by applying it to several existing CNN architectures and training these networks from scratch using the CIFAR, ILSVRC and MIT Places datasets. Our results show similar or higher accuracy than conventional CNNs with much less compute. Applying our method to an improved version of VGG-11 network using global max-pooling, we achieve comparable validation accuracy using 41% less compute and only 24% of the original VGG-11 model parameters; another variant of our method gives a 1 percentage point increase in accuracy over our improved VGG-11 model, giving a top-5 center-crop validation accuracy of 89.7% while reducing computation by 16% relative to the original VGG-11 model. Applying our method to the GoogLeNet architecture for ILSVRC, we achieved comparable accuracy with 26% less compute and 41% fewer model parameters. Applying our method to a near state-of-the-art network for CIFAR, we achieved comparable accuracy with 46% less compute and 55% fewer parameters.",
            "references": [
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "eb42cf88027de515750f230b23b1a057dc782108",
                "f075f89b4f4026748cbf2fb9f989a9934c42ee8f",
                "021fc345d40d3e6332cd2ef276e2eaa5e71102e4",
                "ebcea2d842d3d4e320500086aff0deb4cb4412ff",
                "5d90f06bb70a0a3dced62413346235c02b1aa086",
                "d6f2f611da110b5b5061731be3fc4c7f45d8ee23",
                "23ffaa0fe06eae05817f527a47ac3291077f9e58",
                "5a434953b58c72fe2089531d6c4b4fc1325defcb"
            ]
        },
        {
            "id": "b64601d509711468f5d085261d463846f36785b2",
            "title": "Efficient and accurate approximations of nonlinear convolutional networks",
            "authors": [
                "Xiangyu Zhang",
                "Jianhua Zou",
                "Xiang Ming",
                "Kaiming He",
                "Jian Sun"
            ],
            "date": "2015",
            "abstract": "This paper aims to accelerate the test-time computation of deep convolutional neural networks (CNNs). Unlike existing methods that are designed for approximating linear filters or linear responses, our method takes the nonlinear units into account. We minimize the reconstruction error of the nonlinear responses, subject to a low-rank constraint which helps to reduce the complexity of filters. We develop an effective solution to this constrained nonlinear optimization problem. An algorithm is also presented for reducing the accumulated error when multiple layers are approximated. A whole-model speedup ratio of 4\u00d7 is demonstrated on a large network trained for ImageNet, while the top-5 error rate is only increased by 0.9%. Our accelerated model has a comparably fast speed as the \u201cAlexNet\u201d [11], but is 4.7% more accurate.",
            "references": [
                "e5ae8ab688051931b4814f6d32b18391f8d1fa8d",
                "021fc345d40d3e6332cd2ef276e2eaa5e71102e4",
                "eb42cf88027de515750f230b23b1a057dc782108",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
                "14d9be7962a4ec5a6e55755f4c7588ea00793652",
                "d67175d17c450ab0ac9c256103828f9e9a0acb85",
                "5e83ab70d0cbc003471e87ec306d27d9c80ecb16",
                "e15cf50aa89fee8535703b9f9512fca5bfc43327",
                "fbeaa499e10e98515f7e1c4ad89165e8c0677427"
            ]
        },
        {
            "id": "5b791cd374c7109693aaddee2c12d659ae4e3ec0",
            "title": "Grid Long Short-Term Memory",
            "authors": [
                "Nal Kalchbrenner",
                "Ivo Danihelka",
                "Alex Graves"
            ],
            "date": "2016",
            "abstract": "This paper introduces Grid Long Short-Term Memory, a network of LSTM cells arranged in a multidimensional grid that can be applied to vectors, sequences or higher dimensional data such as images. The network differs from existing deep LSTM architectures in that the cells are connected between network layers as well as along the spatiotemporal dimensions of the data. The network provides a unified way of using LSTM for both deep and sequential computation. We apply the model to algorithmic tasks such as 15-digit integer addition and sequence memorization, where it is able to significantly outperform the standard LSTM. We then give results for two empirical tasks. We find that 2D Grid LSTM achieves 1.47 bits per character on the Wikipedia character prediction benchmark, which is state-of-the-art among neural approaches. In addition, we use the Grid LSTM to define a novel two-dimensional translation model, the Reencoder, and show that it outperforms a phrase-based reference system on a Chinese-to-English translation task.",
            "references": [
                "cea967b59209c6be22829699f05b8b1ac4dc092d",
                "44d2abe2175df8153f465f6c39b68b76a0d40ab9",
                "a7976c2bacfbb194ddbe7fd10c2e50a545cf4081",
                "0d0b3ff23fbf1ec7a0dfebd923a3ef224306491a",
                "e0e5dd8b206806372b3e20b9a2fbdbd0cf9ce1de",
                "4177ec52d1b80ed57f2e72b0f9a42365f1a8598d",
                "d14c7e5f5cace4c925abc74c88baa474e9f31a28",
                "5e83ab70d0cbc003471e87ec306d27d9c80ecb16",
                "d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0",
                "89b1f4740ae37fd04f6ac007577bdd34621f0861"
            ]
        },
        {
            "id": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
            "title": "Neural Machine Translation by Jointly Learning to Align and Translate",
            "authors": [
                "Dzmitry Bahdanau",
                "Kyunghyun Cho",
                "Yoshua Bengio"
            ],
            "date": "2015",
            "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
            "references": [
                "1eb09fecd75eb27825dce4f964b97f4f5cc399d7",
                "5f08df805f14baa826dbddcb002277b15d3f1556",
                "944a1cfd79dbfb6fef460360a0765ba790f4027a",
                "0b544dfe355a5070b60986319a3f51fb45d1348e",
                "6122c95ac6475e965bf4e120f7a588d29bb00ecc",
                "d4a258df43cc14e46988de9a4a7b2f0ea817529b",
                "7b4f3d0e4e2486a8d5d3f8e00549cf9a117bf88f",
                "cea967b59209c6be22829699f05b8b1ac4dc092d",
                "a4b828609b60b06e61bea7a4029cc9e1cad5df87",
                "396aabd694da04cdb846cb724ca9f866f345cbd5"
            ]
        },
        {
            "id": "1956c239b3552e030db1b78951f64781101125ed",
            "title": "Addressing the Rare Word Problem in Neural Machine Translation",
            "authors": [
                "Thang Luong",
                "Ilya Sutskever",
                "Quoc V. Le",
                "Oriol Vinyals",
                "Wojciech Zaremba"
            ],
            "date": "2015",
            "abstract": "Neural Machine Translation (NMT) is a new approach to machine translation that has shown promising results that are comparable to traditional approaches. A significant weakness in conventional NMT systems is their inability to correctly translate very rare words: end-to-end NMTs tend to have relatively small vocabularies with a single unk symbol that represents every possible out-of-vocabulary (OOV) word. In this paper, we propose and implement an effective technique to address this problem. We train an NMT system on data that is augmented by the output of a word alignment algorithm, allowing the NMT system to emit, for each OOV word in the target sentence, the position of its corresponding word in the source sentence. This information is later utilized in a post-processing step that translates every OOV word using a dictionary. Our experiments on the WMT\u201914 English to French translation task show that this method provides a substantial improvement of up to 2.8 BLEU points over an equivalent NMT system that does not use this technique. With 37.5 BLEU points, our NMT system is the first to surpass the best result achieved on a WMT\u201914 contest task.",
            "references": [
                "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
                "1938624bb9b0f999536dcc8d8f519810bb4e1b3b",
                "5f08df805f14baa826dbddcb002277b15d3f1556",
                "cea967b59209c6be22829699f05b8b1ac4dc092d",
                "944a1cfd79dbfb6fef460360a0765ba790f4027a",
                "1401b98a6eb0b0ddaf5bdfd559ed1766434446b8",
                "97cedf99252026f58e8154bc61d49cf885d42030",
                "71480da09af638260801af1db8eff6acb4e1122f",
                "396aabd694da04cdb846cb724ca9f866f345cbd5",
                "a4b828609b60b06e61bea7a4029cc9e1cad5df87"
            ]
        },
        {
            "id": "54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745",
            "title": "Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)",
            "authors": [
                "Junhua Mao",
                "Wei Xu",
                "Yi Yang",
                "Jiang Wang",
                "Alan L. Yuille"
            ],
            "date": "2015",
            "abstract": "In this paper, we present a multimodal Recurrent Neural Network (m-RNN) model for generating novel image captions. It directly models the probability distribution of generating a word given previous words and an image. Image captions are generated by sampling from this distribution. The model consists of two sub-networks: a deep recurrent neural network for sentences and a deep convolutional network for images. These two sub-networks interact with each other in a multimodal layer to form the whole m-RNN model. The effectiveness of our model is validated on four benchmark datasets (IAPR TC-12, Flickr 8K, Flickr 30K and MS COCO). Our model outperforms the state-of-the-art methods. In addition, we apply the m-RNN model to retrieval tasks for retrieving images or sentences, and achieves significant performance improvement over the state-of-the-art methods which directly optimize the ranking objective function for retrieval. The project page of this work is: www.stat.ucla.edu/~junhua.mao/m-RNN.html .",
            "references": [
                "82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9",
                "f142c849ffef66f7520aff4e0b40ac964ccb8cc1",
                "f4af49a1ead3c81cc5d023878cb67c5646dd8a04",
                "2e36ea91a3c8fbff92be2989325531b4002e2afc",
                "cea967b59209c6be22829699f05b8b1ac4dc092d",
                "d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0",
                "55e022fb7581bb9e1fce678d21fb25ffbb3fbb88",
                "f01fc808592ea7c473a69a6e7484040a435f36d9",
                "15f102c3c9f4d4fe6ba105e221df48c6e8902b3b",
                "abd1c342495432171beb7ca8fd9551ef13cbd0ff"
            ]
        },
        {
            "id": "1938624bb9b0f999536dcc8d8f519810bb4e1b3b",
            "title": "On Using Very Large Target Vocabulary for Neural Machine Translation",
            "authors": [
                "S{\\'e}bastien Jean",
                "Kyunghyun Cho",
                "Roland Memisevic",
                "Yoshua Bengio"
            ],
            "date": "2015",
            "abstract": "Neural machine translation, a recently proposed approach to machine translation based purely on neural networks, has shown promising results compared to the existing approaches such as phrase-based statistical machine translation. Despite its recent success, neural machine translation has its limitation in handling a larger vocabulary, as training complexity as well as decoding complexity increase proportionally to the number of target words. In this paper, we propose a method based on importance sampling that allows us to use a very large target vocabulary without increasing training complexity. We show that decoding can be efficiently done even with the model having a very large target vocabulary by selecting only a small subset of the whole target vocabulary. The models trained by the proposed approach are empirically found to outperform the baseline models with a small vocabulary as well as the LSTM-based neural machine translation models. Furthermore, when we use the ensemble of a few models with very large target vocabularies, we achieve the state-of-the-art translation performance (measured by BLEU) on the English!German translation and almost as high performance as state-of-the-art English!French translation system.",
            "references": [
                "1956c239b3552e030db1b78951f64781101125ed",
                "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
                "cea967b59209c6be22829699f05b8b1ac4dc092d",
                "1eb09fecd75eb27825dce4f964b97f4f5cc399d7",
                "944a1cfd79dbfb6fef460360a0765ba790f4027a",
                "53ca064b9f1b92951c1997e90b776e95b0880e52",
                "a4b828609b60b06e61bea7a4029cc9e1cad5df87",
                "0b544dfe355a5070b60986319a3f51fb45d1348e",
                "699d5ab38deee78b1fd17cc8ad233c74196d16e9",
                "b3e89f05876d47b9bd6ece225aaeee457a6824e8"
            ]
        },
        {
            "id": "c34e41312b47f60986458759d5cc546c2b53f748",
            "title": "End-to-end learning of semantic role labeling using recurrent neural networks",
            "authors": [
                "Jie Zhou",
                "Wei Xu"
            ],
            "date": "2015",
            "abstract": "Semantic role labeling (SRL) is one of the basic natural language processing (NLP) problems. To this date, most of the successful SRL systems were built on top of some form of parsing results (Koomen et al., 2005; Palmer et al., 2010; Pradhan et al., 2013), where pre-defined feature templates over the syntactic structure are used. The attempts of building an end-to-end SRL learning system without using parsing were less successful (Collobert et al., 2011). In this work, we propose to use deep bi-directional recurrent network as an end-to-end system for SRL. We take only original text information as input feature, without using any syntactic knowledge. The proposed algorithm for semantic role labeling was mainly evaluated on CoNLL-2005 shared task and achieved F1 score of 81.07. This result outperforms the previous state-of-the-art system from the combination of different parsing trees or models. We also obtained the same conclusion with F1 = 81.27 on CoNLL2012 shared task. As a result of simplicity, our model is also computationally efficient that the parsing speed is 6.7k tokens per second. Our analysis shows that our model is better at handling longer sentences than traditional models. And the latent variables of our model implicitly capture the syntactic structure of a sentence.",
            "references": [
                "cea967b59209c6be22829699f05b8b1ac4dc092d",
                "c4100faa2cc35bc72e61dcbb173f1fee5e8e8840",
                "b5c6f0d18fd783536b4e6c2205d75b7c4477c6d2",
                "bc1022b031dc6c7019696492e8116598097a8c12",
                "57458bc1cffe5caa45a885af986d70f723f406b4",
                "32de44f01a96d4473d21099d15e25bc2b9f08e2f",
                "dee93d4481ac590f6debcd2816f1f8fd27b627d9",
                "8a93cd1b6fbf7c8c86637bae18d979dafeb9a7c1",
                "c92970286c535992a86539b761357761e97a37ee",
                "7ed7a41c275f2870b840a5e6c3eaec8888c9480c"
            ]
        },
        {
            "id": "944a1cfd79dbfb6fef460360a0765ba790f4027a",
            "title": "Recurrent Continuous Translation Models",
            "authors": [
                "Nal Kalchbrenner",
                "Phil Blunsom"
            ],
            "date": "2013",
            "abstract": "We introduce a class of probabilistic continuous translation models called Recurrent Continuous Translation Models that are purely based on continuous representations for words, phrases and sentences and do not rely on alignments or phrasal translation units. The models have a generation and a conditioning aspect. The generation of the translation is modelled with a target Recurrent Language Model, whereas the conditioning on the source sentence is modelled with a Convolutional Sentence Model. Through various experiments, we show first that our models obtain a perplexity with respect to gold translations that is > 43% lower than that of stateof-the-art alignment-based translation models. Secondly, we show that they are remarkably sensitive to the word order, syntax, and meaning of the source sentence despite lacking alignments. Finally we show that they match a state-of-the-art system when rescoring n-best lists of translations.",
            "references": [
                "5f08df805f14baa826dbddcb002277b15d3f1556",
                "1401b98a6eb0b0ddaf5bdfd559ed1766434446b8",
                "d4a258df43cc14e46988de9a4a7b2f0ea817529b",
                "6053d1693c0fab0c21ebbea0ba5408b441a3542b",
                "cd96a6e0b6bb099c515be8770764d2fd18e7b878",
                "d1275b2a2ab53013310e759e5c6878b96df643d4",
                "ab7b5917515c460b90451e67852171a531671ab8",
                "27e38351e48fe4b7da2775bf94341738bc4da07e",
                "79c0b2f44bbc2bc51de554b88ebe46204413f884",
                "57458bc1cffe5caa45a885af986d70f723f406b4"
            ]
        },
        {
            "id": "a739ae988ba0e3ff232f4507627dfc282ba7b3f4",
            "title": "Depth-Gated LSTM",
            "authors": [
                "Kaisheng Yao",
                "Trevor Cohn",
                "Ekaterina Vylomova",
                "Kevin Duh",
                "Chris Dyer"
            ],
            "date": "2015",
            "abstract": "In this short note, we present an extension of long short-term memory (LSTM) neural networks to using a depth gate to connect memory cells of adjacent layers. Doing so introduces a linear dependence between lower and upper layer recurrent units. Importantly, the linear dependence is gated through a gating function, which we call depth gate. This gate is a function of the lower layer memory cell, the input to and the past memory cell of this layer. We conducted experiments and verified that this new architecture of LSTMs was able to improve machine translation and language modeling performances.",
            "references": [
                "5b791cd374c7109693aaddee2c12d659ae4e3ec0",
                "8c571314311f507731296b21b56ab2c326b97392",
                "44d2abe2175df8153f465f6c39b68b76a0d40ab9",
                "cea967b59209c6be22829699f05b8b1ac4dc092d",
                "533ee188324b833e059cb59b654e6160776d5812",
                "89b1f4740ae37fd04f6ac007577bdd34621f0861",
                "9819b600a828a57e1cde047bbe710d3446b30da5",
                "1eb09fecd75eb27825dce4f964b97f4f5cc399d7",
                "e0945081b5b87187a53d4329cf77cd8bff635795",
                "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5"
            ]
        },
        {
            "id": "85315b64a4c73cb86f156ef5b0a085d6ebc8a65d",
            "title": "A Neural Conversational Model",
            "authors": [
                "Oriol Vinyals",
                "Quoc V. Le"
            ],
            "date": "2015",
            "abstract": "Conversational modeling is an important task in natural language understanding and machine intelligence. Although previous approaches exist, they are often restricted to specific domains (e.g., booking an airline ticket) and require hand-crafted rules. In this paper, we present a simple approach for this task which uses the recently proposed sequence to sequence framework. Our model converses by predicting the next sentence given the previous sentence or sentences in a conversation. The strength of our model is that it can be trained end-to-end and thus requires much fewer hand-crafted rules. We find that this straightforward model can generate simple conversations given a large conversational training dataset. Our preliminary results suggest that, despite optimizing the wrong objective function, the model is able to converse well. It is able extract knowledge from both a domain specific dataset, and from a large, noisy, and general domain dataset of movie subtitles. On a domain-specific IT helpdesk dataset, the model can find a solution to a technical problem via conversations. On a noisy open-domain movie transcript dataset, the model can perform simple forms of common sense reasoning. As expected, we also find that the lack of consistency is a common failure mode of our model.",
            "references": [
                "cea967b59209c6be22829699f05b8b1ac4dc092d",
                "d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0",
                "1956c239b3552e030db1b78951f64781101125ed",
                "ba49d3823d43515e447296ca4e1e55d3f1fd8c4d",
                "1938624bb9b0f999536dcc8d8f519810bb4e1b3b",
                "944a1cfd79dbfb6fef460360a0765ba790f4027a",
                "47570e7f63e296f224a0e7f9a0d08b0de3cbaf40",
                "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
                "5247a6e3a60ff0381355e66bfc313bf27512ae0c",
                "9819b600a828a57e1cde047bbe710d3446b30da5"
            ]
        },
        {
            "id": "f9a1b3850dfd837793743565a8af95973d395a4e",
            "title": "LSTM Neural Networks for Language Modeling",
            "authors": [
                "Martin Sundermeyer",
                "Ralf Schl{\\\"u}ter",
                "Hermann Ney"
            ],
            "date": "2012",
            "abstract": "Neural networks have become increasingly popular for the task of language modeling. Whereas feed-forward networks only exploit a fixed context length to predict the next word of a sequence, conceptually, standard recurrent neural networks can take into account all of the predecessor words. On the other hand, it is well known that recurrent networks are difficult to train and therefore are unlikely to show the full potential of recurrent models. These problems are addressed by a the Long Short-Term Memory neural network architecture. In this work, we analyze this type of network on an English and a large French language modeling task. Experiments show improvements of about 8 % relative in perplexity over standard recurrent neural network LMs. In addition, we gain considerable improvements in WER on top of a state-of-the-art speech recognition system.",
            "references": [
                "9819b600a828a57e1cde047bbe710d3446b30da5",
                "e4a94d6eef25cdebdde2c91fb3c45a737d5e3141",
                "c19fbefdeead6a4154a22a9c8551a18b1530033a",
                "07ca885cb5cc4328895bfaec9ab752d5801b14cd",
                "0fcc184b3b90405ec3ceafd6a4007c749df7c363",
                "2f83f6e1afadf0963153974968af6b8342775d82",
                "d0be39ee052d246ae99c082a565aba25b811be2d",
                "047655e733a9eed9a500afd916efa566915b9110",
                "0d6203718c15f137fda2f295c96269bc2b254644",
                "4af41f4d838daa7ca6995aeb4918b61989d1ed80"
            ]
        },
        {
            "id": "96494e722f58705fa20302fe6179d483f52705b4",
            "title": "Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks",
            "authors": [
                "Alex Graves",
                "Santiago Fern{\\'a}ndez",
                "Faustino J. Gomez",
                "J{\\\"u}rgen Schmidhuber"
            ],
            "date": "2006",
            "abstract": "Many real-world sequence learning tasks require the prediction of sequences of labels from noisy, unsegmented input data. In speech recognition, for example, an acoustic signal is transcribed into words or sub-word units. Recurrent neural networks (RNNs) are powerful sequence learners that would seem well suited to such tasks. However, because they require pre-segmented training data, and post-processing to transform their outputs into label sequences, their applicability has so far been limited. This paper presents a novel method for training RNNs to label unsegmented sequences directly, thereby solving both problems. An experiment on the TIMIT speech corpus demonstrates its advantages over both a baseline HMM and a hybrid HMM-RNN.",
            "references": [
                "8fe2ea0a67954f1380b3387e3262f1cdb9f9b3e5"
            ]
        }
    ]
}